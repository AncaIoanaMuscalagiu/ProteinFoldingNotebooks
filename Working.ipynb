{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO2A7hlAD8ySXWQ+0ZdYr0D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AncaIoanaMuscalagiu/ProteinFoldingNotebooks/blob/main/Working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dnSCV-j5G7g-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# import torchvision  # torch package for vision related things\n",
        "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
        "from torch import nn  # All neural network modules\n",
        "import random\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_LSTM_onlyLastHidden(nn.Module):\n",
        "    \"\"\"\n",
        "    LSTM version that just uses the information from the last hidden state\n",
        "    since the last hidden state has information from all previous states\n",
        "    basis for BiDirectional LSTM\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNN_LSTM_onlyLastHidden, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        # change basic RNN to LSTM\n",
        "        # num_layers Default: 1\n",
        "        # bias Default: True\n",
        "        # batch_first Default: False\n",
        "        # dropout Default: 0\n",
        "        # bidirectional Default: False\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        # remove the sequence_length\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get data to cuda if possible\n",
        "        x = x.to(device)\n",
        "        # print(\"input x.size() = \", x.size())\n",
        "        # Set initial hidden and cell states\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        # LSTM needs a separate cell state (LSTM needs both hidden and cell state)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "        # Forward propagate LSTM\n",
        "        # need to give LSTM both hidden and cell state (h0, c0)\n",
        "        out, _ = self.lstm(\n",
        "            x, (h0, c0)\n",
        "        )  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "        \n",
        "        # Decode the hidden state of the last time step\n",
        "        # no need to reshape the out or concat\n",
        "        # out is going to take all mini-batches at the same time + last layer + all features\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        # print(\"forward out = \", out)\n",
        "        return out\n",
        "\n",
        "    def sample_action(self, obs, epsilon):\n",
        "        # print(\"Sample Action called+++\")\n",
        "        \"\"\"\n",
        "        greedy epsilon choose\n",
        "        \"\"\"\n",
        "        coin = random.random()\n",
        "        if coin < epsilon:\n",
        "            # print(\"coin < epsilon\", coin, epsilon)\n",
        "            # for 3actionStateEnv use [0,1,2]\n",
        "            explore_action = random.randint(0,2)\n",
        "            # print(\"explore_action = \", explore_action)\n",
        "            return explore_action\n",
        "        else:\n",
        "            # print(\"exploit\")\n",
        "            out = self.forward(obs)\n",
        "            return out.argmax().item()\n",
        "\n"
      ],
      "metadata": {
        "id": "42uYjuzIJVu_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import os # for creating directories\n",
        "import sys\n",
        "import datetime\n",
        "\n",
        "# time the program\n",
        "from time import time\n"
      ],
      "metadata": {
        "id": "dSsVgo6RJdbi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq = \"HHPPHH\"\n",
        "seed = 42\n",
        "num_episodes = 10000\n",
        "algo = \"50mer-DQN-Seed42-600K\"\n",
        "use_early_stop = 0\n"
      ],
      "metadata": {
        "id": "_G9b33RVJqY6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_dir = f\"./{datetime.datetime.now().strftime('%m%d-%H%M')}-\"\n",
        "# construct subdir with seq and seed\n",
        "config_str = f\"{seq[:6]}-{algo}-seed{seed}-{num_episodes}epi\"\n",
        "save_path = base_dir + config_str + \"/\"\n",
        "\n",
        "# whether to show or save the matplotlib plots\n",
        "display_mode = \"show\"  # save for CMD, show for ipynb\n",
        "if display_mode == \"save\":\n",
        "    save_fig = True\n",
        "else:\n",
        "    save_fig = False\n",
        "\n"
      ],
      "metadata": {
        "id": "-1iscOqKJ_C4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "max_steps_per_episode = len(seq)\n",
        "\n",
        "learning_rate = 0.0005\n",
        "\n",
        "mem_start_train = max_steps_per_episode * 50  # for memory.size() start training\n",
        "TARGET_UPDATE = 100  # fix to 100\n",
        "\n",
        "# capped at 50,000 for <=48mer\n",
        "buffer_limit = int(min(50000, num_episodes // 10))  # replay-buffer size\n",
        "\n",
        "# Exploration parameters\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0.01\n",
        "\n",
        "# render settings\n",
        "show_every = num_episodes // 1000  # for plot_print_rewards_stats\n",
        "pause_t = 0.0\n",
        "# metric for evaluation\n",
        "rewards_all_episodes = np.zeros(\n",
        "    (num_episodes,),\n",
        "    # dtype=np.int32\n",
        ")\n",
        "reward_max = 0\n",
        "# keep track of trapped SAW\n",
        "num_trapped = 0\n",
        "# early_stopped\n",
        "num_early_stopped = 0\n",
        "\n",
        "warmRestart = True\n",
        "decay_mode = \"exponential\"  # exponential, cosine, linear\n",
        "num_restarts = 1  # for cosine decay warmRestart=True\n",
        "exploration_decay_rate = 5  # for exponential decay\n",
        "start_decay = 0  # for exponential and linear\n",
        "print(f\"decay_mode={decay_mode} warmRestart={warmRestart}\")\n",
        "print(f\"num_restarts={num_restarts} exploration_decay_rate={exploration_decay_rate} start_decay={start_decay}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYN4gjlEKIJ0",
        "outputId": "0715530a-726f-4465-ff7b-61d391e8b5a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decay_mode=exponential warmRestart=True\n",
            "num_restarts=1 exploration_decay_rate=5 start_decay=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "import matplotlib.ticker as plticker\n",
        "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator, MaxNLocator)\n",
        "\n",
        "\n",
        "\n",
        "def ExponentialDecay(episode, num_episodes,\n",
        "                min_exploration_rate, max_exploration_rate,\n",
        "                exploration_decay_rate=5,\n",
        "                start_decay=0):\n",
        "    decay_duration = num_episodes - start_decay\n",
        "    exploration_rate = max_exploration_rate\n",
        "    if episode > start_decay:\n",
        "        exploration_rate = min_exploration_rate + \\\n",
        "            (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate*(episode-start_decay)/decay_duration)\n",
        "    return exploration_rate\n",
        "\n",
        "def LinearDecay(episode, num_episodes,\n",
        "                min_exploration_rate, max_exploration_rate,\n",
        "                start_decay=0):\n",
        "    decay_duration = num_episodes - start_decay\n",
        "    exploration_rate = max_exploration_rate\n",
        "    if episode > start_decay:\n",
        "        exploration_rate = min_exploration_rate + \\\n",
        "                            (decay_duration-(episode-start_decay))/decay_duration\n",
        "        # print(\"(decay_duration-(episode-start_decay))/decay_duration = \", (decay_duration-(episode-start_decay))/decay_duration)\n",
        "    # print(\"exploration_rate = \", exploration_rate)\n",
        "    return exploration_rate\n",
        "\n",
        "\n",
        "def Plot_Anneal_Schedule(num_episodes, eta_min=0.01, eta_max=1.0, mode=\"save\", save_path=\"\", warmRestart=True,\n",
        "                         decay_mode=\"cosine\",\n",
        "                         num_restarts=10,\n",
        "                         exploration_decay_rate=5,\n",
        "                         start_decay=0):\n",
        "    print(\"warmRestart = \", warmRestart)\n",
        "    # Exploration parameters\n",
        "    max_exploration_rate = eta_max\n",
        "    min_exploration_rate = eta_min\n",
        "\n",
        "    y =np.zeros(\n",
        "        (num_episodes,),\n",
        "    )\n",
        "\n",
        "    if decay_mode == \"exponential\":\n",
        "        for n_episode in range(num_episodes):\n",
        "            y[n_episode] = ExponentialDecay(\n",
        "                n_episode,\n",
        "                num_episodes,\n",
        "                min_exploration_rate,\n",
        "                max_exploration_rate,\n",
        "                exploration_decay_rate=exploration_decay_rate,\n",
        "                start_decay=start_decay,\n",
        "            )\n",
        "    elif decay_mode == \"linear\":\n",
        "        for n_episode in range(num_episodes):\n",
        "            y[n_episode] = LinearDecay(\n",
        "                n_episode,\n",
        "                num_episodes,\n",
        "                min_exploration_rate,\n",
        "                max_exploration_rate,\n",
        "                start_decay=start_decay,\n",
        "            )\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    plt.yticks(np.arange(-.1, 1.1, 0.1))\n",
        "\n",
        "    ax.plot(np.arange(num_episodes), y)\n",
        "    ax.set(xlabel='Episode', ylabel='epsilon',\n",
        "        # title=f'Epsilon Decay with {decay_mode}Decay warmRestart={warmRestart}')\n",
        "        title=f'Epsilon Decay with {decay_mode}Decay')\n",
        "    ax.grid()\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "HklXmLJUKbzU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator, MaxNLocator)\n",
        "\n",
        "\n",
        "def plot_moving_avg(scores, n=500, mode=\"show\", save_path=\"\"):\n",
        "    print(\"means = \", scores.mean())\n",
        "\n",
        "    # useful utility function for graphing the average\n",
        "    def moving_average(a, n=n):\n",
        "        ret = np.cumsum(a, dtype=float)\n",
        "        ret[n:] = ret[n:] - ret[:-n]\n",
        "        return ret[n - 1:] / n\n",
        "\n",
        "    plt.plot(moving_average(scores, n=n))\n",
        "    # plt.plot(moving_average(opt_scores, n=500))\n",
        "    # plt.plot(moving_average(rand_scores, n=500))\n",
        "    if mode == \"show\":\n",
        "        plt.show()\n",
        "    elif mode == \"save\":\n",
        "        # save the pdf fig with seq name\n",
        "        plt.savefig(save_path + \"moving_avg-\" + str(n) + \".png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def log_rewards_frequency(rewards_all_episodes):\n",
        "    # review all episodes' rewards\n",
        "    print(\"$$$ rewards_all_episodes: \", rewards_all_episodes)\n",
        "    print(\"$$$ rewards_all_episodes last 10 rewards = \",\n",
        "          rewards_all_episodes[-10:])\n",
        "    # count the frequency of unique rewards\n",
        "    unique_elements, counts_elements = np.unique(\n",
        "                                            rewards_all_episodes,\n",
        "                                            return_counts=True)\n",
        "    print(\"Frequency of unique rewards of rewards_all_episodes:\")\n",
        "    with np.printoptions(suppress=True):\n",
        "        print(np.asarray((unique_elements, counts_elements)))\n",
        "\n",
        "\n",
        "def plot_rewards_histogram(rewards_all_episodes, mode=\"show\", save_path=\"\", config_str=\"\"):\n",
        "    # plot the histogram of rewards_all_episodes\n",
        "    # number of bins derived from https://stackoverflow.com/questions/30112420/histogram-for-discrete-values-with-matplotlib\n",
        "    data = rewards_all_episodes\n",
        "    d = np.diff(np.unique(data)).min()\n",
        "    left_of_first_bin = data.min() - float(d)/2\n",
        "    right_of_last_bin = data.max() + float(d)/2\n",
        "\n",
        "    # Width, height in inches.\n",
        "    # default: [6.4, 4.8]\n",
        "    fig_width = 6.4\n",
        "    fig_height = 4.8\n",
        "    # adjust the height of the histogram\n",
        "    if right_of_last_bin - left_of_first_bin > 10:\n",
        "        fig_width = 8\n",
        "        fig_height = 5\n",
        "    elif right_of_last_bin - left_of_first_bin > 20:\n",
        "        fig_width = 12\n",
        "        fig_height = 6\n",
        "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
        "\n",
        "    # the histogram of the data\n",
        "    n, bins, patches = ax.hist(\n",
        "        data,\n",
        "        np.arange(left_of_first_bin, right_of_last_bin + d, d),\n",
        "        density=True,\n",
        "        facecolor='g',\n",
        "    )\n",
        "\n",
        "    # Make a plot with major ticks that are multiples of 20 and minor ticks that\n",
        "    # are multiples of 5.  Label major ticks with '.0f' formatting but don't label\n",
        "    # minor ticks.  The string is used directly, the `StrMethodFormatter` is\n",
        "    # created automatically.\n",
        "    if right_of_last_bin - left_of_first_bin > 20:\n",
        "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    else:\n",
        "        ax.xaxis.set_major_locator(MultipleLocator(1))  # multiple of 1\n",
        "    ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:.0f}'))\n",
        "\n",
        "    # For the minor ticks, use no labels; default NullFormatter.\n",
        "    ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
        "\n",
        "    ax.set_xlabel('Rewards')\n",
        "    ax.set_ylabel('Frequency (Num of Episodes)')\n",
        "    ax.set_title(f'Histogram of Rewards: {config_str}')\n",
        "\n",
        "    # Tweak spacing to prevent clipping of ylabel\n",
        "    fig.tight_layout()\n",
        "    plt.grid(True)\n",
        "    if mode == \"show\":\n",
        "        plt.show()\n",
        "    elif mode == \"save\":\n",
        "        # save the pdf fig with seq name\n",
        "        plt.savefig(save_path+\"rewards_histogram.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_print_rewards_stats(rewards_all_episodes,\n",
        "                             show_every,\n",
        "                             mode=\"show\",\n",
        "                             save_path=\"\"):\n",
        "    # unpack the args\n",
        "    seq = \"HHPPHH\"\n",
        "    seed = 42\n",
        "    algo = \"ALG0\"\n",
        "    num_episodes = 10000\n",
        "\n",
        "    # Calculate and print the average reward per show_every episodes\n",
        "    rewards_per_N_episodes = np.split(\n",
        "                                np.array(rewards_all_episodes),\n",
        "                                num_episodes/show_every\n",
        "                            )\n",
        "    count = show_every\n",
        "\n",
        "    # for plotting\n",
        "    aggr_ep_rewards = {'ep': [], 'avg': [], 'max': [], 'min': []}\n",
        "\n",
        "    print(\"\\n********Stats per {} episodes********\\n\".format(show_every))\n",
        "    for r in rewards_per_N_episodes:\n",
        "        # print(count, \"avg: \", str(sum(r/show_every)))\n",
        "        # print(count, \"min: \", str(min(r)))\n",
        "        # print(count, \"max: \", str(max(r)))\n",
        "\n",
        "        aggr_ep_rewards['ep'].append(count)\n",
        "        aggr_ep_rewards['avg'].append(sum(r/show_every))\n",
        "        aggr_ep_rewards['min'].append(min(r))\n",
        "        aggr_ep_rewards['max'].append(max(r))\n",
        "\n",
        "        count += show_every\n",
        "\n",
        "    # Width, height in inches.\n",
        "    # default: [6.4, 4.8]\n",
        "    fig_width = 6.4\n",
        "    fig_height = 4.8\n",
        "    # adjust the height of the histogram\n",
        "    if np.array(rewards_all_episodes).max() - np.array(rewards_all_episodes).min() > 10:\n",
        "        fig_width = 6.5\n",
        "        fig_height = 6.5\n",
        "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
        "    # Be sure to only pick integer tick locations\n",
        "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    # ax.yaxis.set_major_locator(MultipleLocator(1))\n",
        "    ax.yaxis.set_minor_locator(MultipleLocator(1))\n",
        "\n",
        "    ax.set_xlabel('Episode Index')\n",
        "    ax.set_ylabel('Episode Reward')\n",
        "\n",
        "    ax.plot(aggr_ep_rewards['ep'], aggr_ep_rewards['avg'], label=\"average rewards\")\n",
        "    ax.plot(aggr_ep_rewards['ep'], aggr_ep_rewards['max'], label=\"max rewards\")\n",
        "    ax.plot(aggr_ep_rewards['ep'], aggr_ep_rewards['min'], label=\"min rewards\")\n",
        "\n",
        "    # Put a legend below current axis\n",
        "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
        "          fancybox=True, shadow=True, ncol=3)\n",
        "\n",
        "    # split the seq into chunks of 10 for the matplotlib title\n",
        "    chunks, chunk_size = len(seq), 10\n",
        "    seq_title_list = [\n",
        "        seq[i:i+chunk_size]+\"\\n\" for i in range(0, chunks, chunk_size)\n",
        "    ]\n",
        "    seq_title_str = ''.join(seq_title_list)\n",
        "    title = \"{}Algo={}, Epi={}, Seed={}\\nShow-every {}\".format(\n",
        "        seq_title_str,\n",
        "        algo,\n",
        "        num_episodes,\n",
        "        seed,\n",
        "        show_every,\n",
        "    )\n",
        "    # print(\"Title: \", title)\n",
        "    plt.title(title)\n",
        "    plt.grid(True, which=\"major\", lw=1.2, linestyle='-')\n",
        "    plt.grid(True, which=\"minor\", lw=0.8, linestyle='--')\n",
        "    plt.tight_layout()\n",
        "    if mode == \"show\":\n",
        "        plt.show()\n",
        "    elif mode == \"save\":\n",
        "        # save the pdf fig with seq name\n",
        "        plt.savefig(\"{}Seq_{}-{}-Eps{}-Seed{}.png\".format(\n",
        "            save_path,  # \"./xxx\"\n",
        "            seq,\n",
        "            algo,\n",
        "            num_episodes,\n",
        "            seed,\n",
        "        ))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def extract_max_per_chunk(rewards_all_episodes,\n",
        "                          num_episodes,\n",
        "                          show_every):\n",
        "    \"\"\"\n",
        "    extract the max per chunk\n",
        "    \"\"\"\n",
        "    rewards_per_N_episodes = np.split(\n",
        "                                rewards_all_episodes,\n",
        "                                num_episodes//show_every\n",
        "                            )\n",
        "    aggr_max = np.zeros((num_episodes//show_every,))\n",
        "\n",
        "    for index, r in enumerate(rewards_per_N_episodes):\n",
        "        aggr_max[index] = np.amax(r)\n",
        "\n",
        "    return aggr_max\n",
        "\n",
        "def avg_std_of_max(seed_42_data,\n",
        "                   seed_1984_data,\n",
        "                   seed_1991_data,\n",
        "                   seed_2021_data,\n",
        "                   num_episodes,\n",
        "                   N_chunks,\n",
        "                   show_every,\n",
        "                   ):\n",
        "    max_seed_42_data = extract_max_per_chunk(seed_42_data,\n",
        "                                            num_episodes,\n",
        "                                            show_every)\n",
        "    max_seed_1984_data = extract_max_per_chunk(seed_1984_data,\n",
        "                                            num_episodes,\n",
        "                                            show_every)\n",
        "    max_seed_1991_data = extract_max_per_chunk(seed_1991_data,\n",
        "                                            num_episodes,\n",
        "                                            show_every)\n",
        "    max_seed_2021_data = extract_max_per_chunk(seed_2021_data,\n",
        "                                            num_episodes,\n",
        "                                            show_every)\n",
        "\n",
        "    print(\"max_data shape = \", max_seed_42_data.shape, max_seed_2021_data.shape)\n",
        "\n",
        "    num_seeds = 4\n",
        "    max_stacked = np.zeros((num_seeds, N_chunks))\n",
        "\n",
        "    max_stacked[0] = max_seed_42_data\n",
        "    max_stacked[1] = max_seed_1984_data\n",
        "    max_stacked[2] = max_seed_1991_data\n",
        "    max_stacked[3] = max_seed_2021_data\n",
        "\n",
        "    avg = np.mean(max_stacked, axis=0)\n",
        "    std = np.std(max_stacked, axis=0)\n",
        "\n",
        "    # print(\"avg = \", avg)\n",
        "    # print(\"std = \", std)\n",
        "\n",
        "    return avg, std\n",
        "\n",
        "def plot_shaded_std(title, N_chunks, show_every, mean_1, std_1, mean_2, std_2,\n",
        "                    mean_3=None, std_3=None):\n",
        "    # import seaborn as sns\n",
        "    # sns.set()\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
        "    # plt.rc('axes', titlesize=24)     # fontsize of the axes title\n",
        "    plt.rc('axes', labelsize=24)    # fontsize of the x and y labels\n",
        "    plt.rc('xtick', labelsize=21)    # fontsize of the tick labels\n",
        "    plt.rc('ytick', labelsize=21)    # fontsize of the tick labels\n",
        "    plt.rc('legend', fontsize=15)    # legend fontsize\n",
        "    # plt.rc('figure', titlesize=48)  # fontsize of the figure title\n",
        "    plt.rcParams[\"figure.figsize\"] = (8, 7)\n",
        "    # plt.rcParams[\"font.family\"] = \"monospace\"\n",
        "\n",
        "    x = np.arange(N_chunks)\n",
        "    x = x*show_every\n",
        "    x = x // 1000  # per K\n",
        "    # print(x)\n",
        "\n",
        "    # plot\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    ax.plot(x, mean_1, color='b', label='RAND')\n",
        "    ax.fill_between(x, mean_1 - std_1, mean_1 + std_1, color='b', alpha=0.2)\n",
        "    ax.plot(x, mean_2, color='r', label='DQN-LSTM')\n",
        "    # ax.plot(x, mean_2, color='r', label='DQN+Pruning+TrapPenalty')\n",
        "    ax.fill_between(x, mean_2 - std_2, mean_2 + std_2, color='r', alpha=0.2)\n",
        "    ax.plot(x, mean_3, color='y', label='DQN-FCN')\n",
        "    # ax.plot(x, mean_3, color='y', label='DQN w/o Pruning/TrapPenalty')\n",
        "    ax.fill_between(x, mean_3 - std_3, mean_3 + std_3, color='y', alpha=0.2)\n",
        "\n",
        "    ax.xaxis.set_major_formatter(ticker.StrMethodFormatter(\"{x:.0f}k\"))\n",
        "\n",
        "    # optional: set the y limit\n",
        "    # ax.set_ylim(-20, -9)\n",
        "\n",
        "    ax.set_xlabel(\"Episode Index\")\n",
        "    ax.set_ylabel(\"Energy\")\n",
        "    ax.legend(loc='lower left')\n",
        "    # ax.legend(loc='upper right')\n",
        "    ax.set_title(title, fontsize=27)\n",
        "\n",
        "    # Tweak spacing to prevent clipping of ylabel\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(title + \"-RANDvsDQN.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "sznuPdRFKc_Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is a Deep Q Learning (DQN) agent including replay memory and a target network\n",
        "# you can write a brief 8-10 line abstract detailing your submission and experiments here\n",
        "# the cod is based on https://github.com/seungeunrho/minimalRL/blob/master/dqn.py, which is released under the MIT licesne\n",
        "# make sure you reference any cod you have studied as above, with one comment line per reference\n",
        "\n",
        "# imports\n",
        "from collections import deque\n",
        "# Note: deque is pronounced as “deck.” The name stands for double-ended queue.\n",
        "import random\n",
        "import pickle\n",
        "# pytorch deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# if gpu is to be used\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# hyperparameters\n",
        "gamma = 0.98    # discount rate\n",
        "batch_size = 32\n",
        "train_times = 10  # number of times train was run in a loop\n",
        "\n",
        "\n",
        "class ReplayBuffer():\n",
        "    \"\"\"\n",
        "    for DQN (off-policy RL), big buffer of experience\n",
        "    you don't update weights of the NN as you run\n",
        "    through the environment, instead you save\n",
        "    your experience of the environment to this ReplayBuffer\n",
        "    It has a max-size to fit in certain examples\n",
        "    \"\"\"\n",
        "    def __init__(self, buffer_limit):\n",
        "        self.buffer = deque(maxlen=buffer_limit)\n",
        "\n",
        "    def put(self, transition):\n",
        "        self.buffer.append(transition)\n",
        "\n",
        "    def sample(self, n):\n",
        "        mini_batch = random.sample(self.buffer, n)\n",
        "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
        "\n",
        "        for transition in mini_batch:\n",
        "            # a tuple that tells us what the state was\n",
        "            # at a particular point in time\n",
        "            # we store the current state, the action we chose,\n",
        "            # the state we ended up in, and whether finished or not\n",
        "            s, a, r, s_prime, done_mask = transition\n",
        "            s_lst.append(s)\n",
        "            a_lst.append([a])\n",
        "            r_lst.append([r])\n",
        "            s_prime_lst.append(s_prime)\n",
        "            done_mask_lst.append([done_mask])\n",
        "\n",
        "        # converting the list to a single numpy.ndarray with numpy.array()\n",
        "        # before converting to a tensor\n",
        "        s_lst = np.array(s_lst)\n",
        "        a_lst = np.array(a_lst)\n",
        "        r_lst = np.array(r_lst)\n",
        "        s_prime_lst = np.array(s_prime_lst)\n",
        "        done_mask_lst = np.array(done_mask_lst)\n",
        "\n",
        "        # print(\"torch.tensor(s_lst, dtype=torch.float) = \", torch.tensor(s_lst, dtype=torch.float))\n",
        "        # print(\"torch.tensor(a_lst) = \", torch.tensor(a_lst))\n",
        "        # print(\"torch.tensor(r_lst) = \", torch.tensor(r_lst))\n",
        "        # print(\"torch.tensor(s_prime_lst, dtype=torch.float) = \", torch.tensor(s_prime_lst, dtype=torch.float))\n",
        "        # print(\"torch.tensor(done_mask_lst) = \", torch.tensor(done_mask_lst))\n",
        "\n",
        "        return torch.tensor(s_lst, device=device, dtype=torch.float), torch.tensor(a_lst, device=device), \\\n",
        "               torch.tensor(r_lst, device=device), torch.tensor(s_prime_lst, device=device, dtype=torch.float), \\\n",
        "               torch.tensor(done_mask_lst, device=device)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def save(self, save_path):\n",
        "        \"\"\"save in .pkl file\"\"\"\n",
        "        with open(save_path, 'wb') as handle:\n",
        "            pickle.dump(self.buffer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "    def load(self, file_path):\n",
        "        \"\"\"load a .pkl file\"\"\"\n",
        "        with open(file_path, 'rb') as handle:\n",
        "            self.buffer = pickle.load(handle)\n",
        "\n",
        "class FCN_QNet(nn.Module):\n",
        "    \"\"\"\n",
        "    action value function, Q(S, a)\n",
        "    produce the actions in parallel as output vector,\n",
        "    and choose the max\n",
        "    \"\"\"\n",
        "    def __init__(self, insize, outsize):\n",
        "        \"\"\"\n",
        "        insize ==> input size\n",
        "            == size of the observation space\n",
        "        outsize ==> output size\n",
        "            == number of actions\n",
        "        \"\"\"\n",
        "        super(FCN_QNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(insize, 256)\n",
        "        self.fc2 = nn.Linear(256, 84)\n",
        "        self.fc3 = nn.Linear(84, outsize)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        standard 3-layer fully connected NN\n",
        "        \"\"\"\n",
        "        x = x.to(device)  # for CUDA\n",
        "        # print(\"input x.size() = \", x.size())\n",
        "        x = x.view(x.size(0),-1)\n",
        "        # may encounter view memory error\n",
        "        # RuntimeError: view size is not compatible with input tensor's size and stride\n",
        "        # (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
        "        # x = x.reshape(x.size(0),-1)\n",
        "        # print(\"after x.view ---> input x.size() = \", x.size())\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def sample_action(self, obs, epsilon):\n",
        "        \"\"\"\n",
        "        greedy epsilon choose\n",
        "        \"\"\"\n",
        "        coin = random.random()\n",
        "        if coin < epsilon:\n",
        "            # print(\"coin < epsilon\", coin, epsilon)\n",
        "            # for 3actionStateEnv use [0,1,2]\n",
        "            return random.randint(0,2)\n",
        "        else:\n",
        "            # print(\"exploit\")\n",
        "            out = self.forward(obs)\n",
        "            return out.argmax().item()\n",
        "\n",
        "def train(q, q_target, memory, optimizer):\n",
        "    \"\"\"\n",
        "    core algorithm of Deep Q-learning\n",
        "\n",
        "    do this training once per evaluation of the environment\n",
        "    run evaluation once and train X times\n",
        "    \"\"\"\n",
        "    for i in range(train_times):\n",
        "        # sample from memory, which is not from the most recent runs\n",
        "        # but from all previous runs in the memory, so you can be\n",
        "        # more sample efficient, because you continuously learn from\n",
        "        # past situations\n",
        "        # key advantage of Off-policy\n",
        "        s,a,r,s_prime,done_mask = memory.sample(batch_size)\n",
        "        # the torch size is [batch_size, rows, cols], ie batch_first\n",
        "        # print(\"DQN train --> s.size = \", s.size())\n",
        "        # print(s)\n",
        "        # print(\"DQN train --> r.size = \", r.size())\n",
        "        # print(r)\n",
        "\n",
        "        # forward once to q\n",
        "        q_out = q(s)\n",
        "        q_a = q_out.gather(1,a)\n",
        "        # forward another time for q_target\n",
        "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
        "        # calculate the target value\n",
        "        # if environment is done, there is no future reward,\n",
        "        # mask the final step reward with done_mask (0.0 if done else 1.0)\n",
        "        target = r + gamma * max_q_prime * done_mask\n",
        "        # L1 loss but smoothed out a bit\n",
        "        loss = F.smooth_l1_loss(q_a, target)\n",
        "        # we will try to improve on Q(s,a)\n",
        "        # how well our Q-function is at guessing the future long-term rewards\n",
        "        # Q_targ() is the target Q network, a 2nd NN to stablize training\n",
        "        # Q(s,a) = R(s,a) + γ*Q_targ(s_prime)*done_mask\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # clip the policy_net.parameters()\n",
        "        # Dec05 2021 found it did not work...\n",
        "        # for param in q.parameters():\n",
        "        #     param.grad.data.clamp_(-1, 1)\n",
        "        optimizer.step()\n"
      ],
      "metadata": {
        "id": "lk718eADK4EA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.lines as mlines\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import io\n",
        "\n",
        "\n",
        "def label_conf_seq(conf_seq, conf_title):\n",
        "    \"\"\"\n",
        "    input:\n",
        "        conf_seq:\n",
        "            the conf sequence as taken from HPSandbox file\n",
        "            list of coordinates --> [(x1,y1), (x3,y2)...]\n",
        "        conf_title: the conf file title\n",
        "    output:\n",
        "        conf with the H/P sequence\n",
        "        list of tuples\n",
        "        [((0, 0), 'H'),\n",
        "        ((0, 1), 'H'),...\n",
        "        ((3, 1), 'P')]\n",
        "    NOTE: the output from label_conf_seq() is the same\n",
        "    as the OrderedDict's items()\n",
        "    \"\"\"\n",
        "    str_seq = conf_title[:-5]\n",
        "\n",
        "    # the sequence length must match\n",
        "    assert len(str_seq) == len(conf_seq)\n",
        "\n",
        "    labelled_conf = []\n",
        "    for index, letter in enumerate(str_seq):\n",
        "        labelled_conf.append((conf_seq[index], letter))\n",
        "\n",
        "    return labelled_conf\n",
        "\n",
        "\n",
        "# map of LFR directions and ints\n",
        "LFR_map = {\n",
        "    \"left\": 0,\n",
        "    \"forward\": 1,\n",
        "    \"right\": 2,\n",
        "    \"error\": -1,\n",
        "    \"0\": \"left\",\n",
        "    \"1\": \"forward\",\n",
        "    \"2\": \"right\",\n",
        "    \"-1\": \"error\",\n",
        "}\n",
        "\n",
        "\n",
        "def move_LFR_direction(p1, p2, move_direction):\n",
        "    \"\"\"\n",
        "    move in Left, Forward, Right directions\n",
        "    input:\n",
        "        p1 is the point two positions earlier\n",
        "        p2 is the point one position earlier\n",
        "        both p1 and p2 are tuples of (x,y)\n",
        "\n",
        "        move_direction:\n",
        "        left: 0,\n",
        "        forward: 1,\n",
        "        right: 2,\n",
        "        # error: -1\n",
        "\n",
        "    return:\n",
        "        p3 is to-be-moved point\n",
        "    \"\"\"\n",
        "    if move_direction not in {0, 1, 2}:\n",
        "        print(\"ILLEGAL MOVE\")\n",
        "        return\n",
        "\n",
        "    # print(\"p1, p2: \", p1, p2)\n",
        "    x1, y1 = p1\n",
        "    x2, y2 = p2\n",
        "\n",
        "    # candidates adjacent_coords\n",
        "    p3_candidates = [\n",
        "        (x2 - 1, y2),\n",
        "        (x2, y2 - 1),\n",
        "        (x2, y2 + 1),\n",
        "        (x2 + 1, y2),\n",
        "    ]\n",
        "    # print(\"p3_candidates = \", p3_candidates)\n",
        "\n",
        "    for candidate in p3_candidates:\n",
        "        # print(\"try p3 candidate \", candidate)\n",
        "        direction = derive_LFR_direction(p1, p2, candidate)\n",
        "        # print(\"direction = \", direction)\n",
        "        if direction == move_direction:\n",
        "            # print(\"found matching p3\")\n",
        "            p3 = candidate\n",
        "\n",
        "    return p3\n",
        "\n",
        "\n",
        "def derive_LFR_direction(p1, p2, p3):\n",
        "    \"\"\"\n",
        "    derive Left, Forward, Right directions\n",
        "    input:\n",
        "        p1 is the point two positions earlier\n",
        "        p2 is the point one position earlier\n",
        "        p3 is the current point\n",
        "        both p1 and p2 are tuples of (x,y)\n",
        "\n",
        "    return:\n",
        "        left: 0,\n",
        "        forward: 1,\n",
        "        right: 2,\n",
        "        error: -1\n",
        "    \"\"\"\n",
        "    # first check for illegal moves\n",
        "    # current point cannot be folded back to p1\n",
        "    if p3 == p1:\n",
        "        # print(\"ILLEGAL: folded back to p1\")\n",
        "        return -1\n",
        "    # current point cannot stay put as p2\n",
        "    if p3 == p2:\n",
        "        # print(\"ILLEGAL: cannot stay put at p2\")\n",
        "        return -1\n",
        "    # cases for cross product\n",
        "    to_left_product = np.array([0, 0, 1], dtype=int)\n",
        "    to_right_product = np.array([0, 0, -1], dtype=int)\n",
        "    to_forward_product = np.array([0, 0, 0], dtype=int)\n",
        "    #print(\"p1, p2, p3: \", p1, p2, p3)\n",
        "    # derive the delta vector\n",
        "    v1 = np.array(p2) - np.array(p1)\n",
        "    v2 = np.array(p3) - np.array(p2)\n",
        "    #print(\"v1, v2: \", v1, v2)\n",
        "    # first pad the v1 and v2 into 3D vector\n",
        "    v1_3d = np.append(v1, [0])\n",
        "    v2_3d = np.append(v2, [0])\n",
        "    #print(\"v1_3d, v2_3d: \", v1_3d, v2_3d)\n",
        "    cross_product = np.cross(v1_3d, v2_3d)\n",
        "    #print(\"cross v1xv2: \", cross_product)\n",
        "    if np.array_equal(cross_product, to_left_product):\n",
        "        return LFR_map[\"left\"]  # \"Left\"\n",
        "    elif np.array_equal(cross_product, to_right_product):\n",
        "        return LFR_map[\"right\"]  # \"Right\"\n",
        "    elif np.array_equal(cross_product, to_forward_product):\n",
        "        return LFR_map[\"forward\"]  # \"Forward\"\n",
        "    else:\n",
        "        return LFR_map[\"error\"]  # \"probably out of range moves\"\n",
        "\n",
        "\n",
        "def directionize_conf_seq(labelled_conf,\n",
        "                          print_table=False):\n",
        "    \"\"\"\n",
        "    input:\n",
        "        labelled_conf:\n",
        "            is a list of tuples of ((x,y), 'H|P')\n",
        "            from label_conf_seq(conf_seq, conf_title)\n",
        "\n",
        "        print_table: whether to\n",
        "            print a table of X, Y, State, and Direction\n",
        "    output:\n",
        "        append column of Left, Forward, Right\n",
        "        to the labelled_conf\n",
        "        e.g.\n",
        "        [\n",
        "            ((0, 0), 'H', None, None),\n",
        "            ((0, 1), 'H', 1, 'forward'),\n",
        "            ((1, 1), 'H', 2, 'right'),\n",
        "            ...\n",
        "        ]\n",
        "    \"\"\"\n",
        "    directionized_conf = []\n",
        "\n",
        "    if print_table:\n",
        "        print(\"X\\tY\\tState\\tDirection(LFR)\")\n",
        "    for index, item in enumerate(labelled_conf):\n",
        "        if index <= 1:\n",
        "            # 0th and 1st monomer have no direction\n",
        "            direction = None\n",
        "        else:\n",
        "            # compute the LFR direction for the move\n",
        "            direction = derive_LFR_direction(\n",
        "                            labelled_conf[index-2][0],\n",
        "                            labelled_conf[index-1][0],\n",
        "                            labelled_conf[index][0]\n",
        "                        )\n",
        "\n",
        "        directionized_conf.append(\n",
        "            (\n",
        "                item[0],\n",
        "                item[1],\n",
        "                direction,\n",
        "                LFR_map.get(str(direction)),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # print(\"directionized_conf is now:\")\n",
        "        # print(directionized_conf)\n",
        "\n",
        "        if print_table:\n",
        "            print('{}\\t{}\\t{}\\t{}\\t{}'.format(\n",
        "                item[0][0],\n",
        "                item[0][1],\n",
        "                item[1],\n",
        "                direction,\n",
        "                LFR_map.get(str(direction)),\n",
        "            ))\n",
        "\n",
        "    # print(\"len of directionized_conf = \", len(directionized_conf))\n",
        "\n",
        "    return directionized_conf\n",
        "\n",
        "\n",
        "def plot_HPSandbox_conf(labelled_conf,\n",
        "                        display_mode=\"draw\",\n",
        "                        pause_t=0.5,\n",
        "                        save_fig=False,\n",
        "                        save_path=\"\",\n",
        "                        score=2022,\n",
        "                        optima_idx=0,\n",
        "                        info={}):\n",
        "    \"\"\"\n",
        "    input:\n",
        "        labelled_conf:\n",
        "            transformed file sequence of xy coords with state:\n",
        "            ((x,y), 'H|P')\n",
        "            e.g:\n",
        "            [((0, 0), 'H'),\n",
        "            ((0, 1), 'H'),...\n",
        "            ((3, 1), 'P')]\n",
        "        display_mode:\n",
        "            draw vs show\n",
        "        pause_t:\n",
        "            seconds to display draw in plt.pause()\n",
        "        save_fig:\n",
        "            whether to save the pdf fig with seq name\n",
        "            otherwise leaves a fig-live.pdf for review\n",
        "    output:\n",
        "        plot.show\n",
        "    \"\"\"\n",
        "\n",
        "    # plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
        "    # plt.rc('axes', titlesize=24)     # fontsize of the axes title\n",
        "    plt.rc('axes', labelsize=25)    # fontsize of the x and y labels\n",
        "    plt.rc('xtick', labelsize=21)    # fontsize of the tick labels\n",
        "    plt.rc('ytick', labelsize=21)    # fontsize of the tick labels\n",
        "    # plt.rc('legend', fontsize=15)    # legend fontsize\n",
        "    # plt.rc('figure', titlesize=48)  # fontsize of the figure title\n",
        "    # plt.rcParams[\"figure.figsize\"] = (8, 7)\n",
        "    # plt.rcParams[\"font.family\"] = \"monospace\"\n",
        "\n",
        "    # print(\"+=+=+=+=+=+ plot_HPSandbox_conf -_-_-_-_-_-\")\n",
        "    x = [t[0][0] for t in labelled_conf]\n",
        "    y = [t[0][1] for t in labelled_conf]\n",
        "    str_seq = ''.join([t[1] for t in labelled_conf])\n",
        "    assert len(str_seq) == info[\"chain_length\"]\n",
        "    H_seq = [t[0] for t in labelled_conf if t[1] == 'H']\n",
        "    P_seq = [t[0] for t in labelled_conf if t[1] == 'P']\n",
        "\n",
        "    # print(\"x: \", x)\n",
        "    # print(\"y: \", y)\n",
        "    # print(\"str_seq: \", str_seq)\n",
        "    # print(\"H_seq: \", H_seq)\n",
        "    # print(\"P_seq: \", P_seq)\n",
        "\n",
        "    # Width, height in inches.\n",
        "    fig_width = 5\n",
        "    fig_height = 5\n",
        "    # fontsize for legend\n",
        "    fontsize = \"xx-small\"\n",
        "    title_font = 12\n",
        "    if len(str_seq) > 10:\n",
        "        fig_width = 10\n",
        "        fig_height = 10\n",
        "        fontsize = \"x-small\"\n",
        "        title_font = 15\n",
        "    if len(str_seq) > 20:\n",
        "        fig_width = 13\n",
        "        fig_height = 13\n",
        "        fontsize = \"small\"\n",
        "        title_font = 18\n",
        "    if len(str_seq) > 30:\n",
        "        fig_width = 16\n",
        "        fig_height = 16\n",
        "        title_font = 21\n",
        "    if len(str_seq) > 40:\n",
        "        fig_width = 18\n",
        "        fig_height = 18\n",
        "        title_font = 24\n",
        "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
        "    plt.subplots_adjust(top=0.9) # use a lower number to make more vertical space\n",
        "\n",
        "    # set x and y limit and center origin\n",
        "    max_xval = np.absolute(x).max()\n",
        "    max_yval = np.absolute(y).max()\n",
        "    ax.set_xlim(-max_xval-1, max_xval+1)\n",
        "    ax.set_ylim(-max_yval-1, max_yval+1)\n",
        "\n",
        "    # grid background\n",
        "    ax.grid(linewidth=0.6, linestyle=':')\n",
        "\n",
        "    # adjust plots with equal axis ratios\n",
        "    #ax.axis('equal')\n",
        "    ax.set_aspect('equal')  # , adjustable='box')\n",
        "\n",
        "    # x and y axis tick at integer level\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    # figure title\n",
        "    # split the seq into chunks of chunk_size for the matplotlib title\n",
        "    # NOTE: here the chunks are fixed sequence length not chain length\n",
        "    chunks, chunk_size = info['seq_length'], 20\n",
        "    # print(f\"chunks={chunks}, chunk_size={chunk_size}\")\n",
        "    pad_len = info['seq_length'] - info['chain_length']\n",
        "\n",
        "    # pad the str_seq\n",
        "    str_seq = str_seq + '_'*pad_len\n",
        "    seq_title_list = [\n",
        "        str_seq[i:i+chunk_size]+\"\\n\" for i in range(0, chunks, chunk_size)\n",
        "    ]\n",
        "    # print(\"seq_title_list = \", seq_title_list)\n",
        "    seq_title_str = ''.join(seq_title_list)\n",
        "\n",
        "    # do the same for padded action_str\n",
        "    # pad the action_str\n",
        "    action_str = ''.join(info[\"actions\"])\n",
        "    padded_action_str = action_str + '_'*pad_len\n",
        "    action_title_list = [\n",
        "        padded_action_str[i:i+chunk_size]+\"\\n\" for i in range(0, chunks, chunk_size)\n",
        "    ]\n",
        "    # print(\"action_title_list = \", action_title_list)\n",
        "    action_title_str = ''.join(action_title_list)\n",
        "\n",
        "    title = \"{}Actions=\\n{}\".format(\n",
        "        seq_title_str,\n",
        "        action_title_str,\n",
        "    )\n",
        "    # print(\"Title: \", title)\n",
        "    ax.set_title(title, fontsize=title_font)\n",
        "\n",
        "    # axis title\n",
        "    ax.set_xlabel(\"x coord\")\n",
        "    ax.set_ylabel(\"y coord\")\n",
        "\n",
        "    # the HP plot consists of three layers\n",
        "\n",
        "    # layer 1: backbone with solid line\n",
        "    ax.plot(\n",
        "        x, y,\n",
        "        color='cornflowerblue',\n",
        "        linewidth=4,\n",
        "        label=\"backbone\",\n",
        "    )\n",
        "    # layer 2: H as solid blue dots\n",
        "    ax.plot(\n",
        "        [h[0] for h in H_seq],\n",
        "        [h[1] for h in H_seq],\n",
        "        'o',\n",
        "        markersize=14,\n",
        "        label=\"H\",\n",
        "    )\n",
        "    # layer 3: P as hollow orange dots\n",
        "    ax.plot(\n",
        "        [p[0] for p in P_seq],\n",
        "        [p[1] for p in P_seq],\n",
        "        'o',\n",
        "        fillstyle='none',\n",
        "        markersize=14,\n",
        "        label=\"P\",\n",
        "    )\n",
        "\n",
        "    # Show H-H bonds\n",
        "    ## Compute all pair distances for the bases in the configuration\n",
        "    coordinates = []\n",
        "    for i in range(len(labelled_conf)):\n",
        "        if labelled_conf[i][1] == 'H':\n",
        "            coordinates.append(labelled_conf[i][0])\n",
        "        else:\n",
        "            coordinates.append((-1000, 1000)) #To get rid of P's\n",
        "    distances = euclidean_distances(coordinates, coordinates)\n",
        "    ## We can extract the H-bonded pairs by looking at the upper-triangular (triu)\n",
        "    ## distance matrix, and taking those = 1, but ignore immediate neighbors (k=2).\n",
        "    bond_idx = np.where(np.triu(distances, k=2) == 1.0)    \n",
        "    for (x,y) in zip(*bond_idx):\n",
        "        xdata = [coordinates[x][0], coordinates[y][0]]\n",
        "        ydata = [coordinates[x][1], coordinates[y][1]]\n",
        "        backbone = mlines.Line2D(xdata, ydata, color = 'r', ls = ':', zorder = 1)\n",
        "        ax.add_line(backbone)\n",
        "\n",
        "    # show the legend\n",
        "    # ax.legend(loc=0, markerscale=0.5, fontsize=fontsize)\n",
        "\n",
        "    # Tweak spacing to prevent clipping of ylabel\n",
        "    fig.tight_layout()\n",
        "\n",
        "    if save_fig:\n",
        "        # save the pdf fig with seq name\n",
        "        plt.savefig(f\"{save_path}/\" +\\\n",
        "            f\"{str_seq[:6]}_{action_str[:6]}_\" +\\\n",
        "            f\"{info['seq_length']}mer_\" +\\\n",
        "            f\"E{int(score)}_ID{optima_idx}.png\",\n",
        "            bbox_inches='tight',\n",
        "        )\n",
        "\n",
        "    if display_mode == \"draw\":\n",
        "        # plt.draw()\n",
        "        # plt.pause(pause_t)\n",
        "        # save as pdf for review\n",
        "        # can open the pdf in another window\n",
        "        # the process is fast enough to get semi-live update rate\n",
        "        # plt.savefig(\"fig-live.pdf\", bbox_inches='tight')\n",
        "        pass\n",
        "    elif display_mode == \"show\":\n",
        "        # show() is blocking, close window manually\n",
        "        pass\n",
        "\n",
        "    # close the plt window\n",
        "    plt.close()\n",
        "\n",
        "def output_CNN(labelled_conf, N):\n",
        "    # print(\"+=+=+=+=+=+ plot_HPSandbox_conf -_-_-_-_-_-\")\n",
        "    x = [t[0][0] for t in labelled_conf]\n",
        "    y = [t[0][1] for t in labelled_conf]\n",
        "    str_seq = '-'.join([t[1] for t in labelled_conf])\n",
        "    H_seq = [t[0] for t in labelled_conf if t[1] == 'H']\n",
        "    P_seq = [t[0] for t in labelled_conf if t[1] == 'P']\n",
        "\n",
        "    # print(\"x: \", x)\n",
        "    # print(\"y: \", y)\n",
        "    # print(\"str_seq: \", str_seq)\n",
        "    # print(\"H_seq: \", H_seq)\n",
        "    # print(\"P_seq: \", P_seq)\n",
        "\n",
        "    # Width, height in inches.\n",
        "    fig_width = 5 * (N/20)\n",
        "    fig_height = 5 * (N/20)\n",
        "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
        "\n",
        "    # set x and y limit and center origin\n",
        "    # Sep30 new consistent plot for CNN\n",
        "    # N is the complete chain length (not labeled_conf!)\n",
        "    top_limit = N-0.5\n",
        "    left_limit = -(N-1.5)\n",
        "    bottom_limit = min(-(N-3.5), -0.5)\n",
        "    right_limit = max(N-4.5, 0.5)\n",
        "    # print(f\"before crop, top={top_limit} left={left_limit} bot={bottom_limit} right={right_limit}\")\n",
        "    top_limit = round(top_limit/2) + 0.5\n",
        "    left_limit = round(left_limit/2) - 0.5\n",
        "    bottom_limit = (round(bottom_limit/2) - 0.5) if bottom_limit != -0.5 else bottom_limit\n",
        "    right_limit = (round(right_limit/2) + 0.5) if right_limit != 0.5 else right_limit\n",
        "    # print(f\"after crop, top={top_limit} left={left_limit} bot={bottom_limit} right={right_limit}\")\n",
        "    ax.set_xlim(left_limit, right_limit)\n",
        "    ax.set_ylim(bottom_limit, top_limit)\n",
        "\n",
        "    # grid background\n",
        "    # ax.grid(linewidth=0.6, linestyle=':')\n",
        "\n",
        "    # adjust plots with equal axis ratios\n",
        "    #ax.axis('equal')\n",
        "    ax.set_aspect('equal')  # , adjustable='box')\n",
        "\n",
        "    # https://stackoverflow.com/questions/9295026/matplotlib-plots-removing-axis-legends-and-white-spaces\n",
        "    plt.axis('off')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax.xaxis.set_ticklabels([])\n",
        "    ax.yaxis.set_ticklabels([])\n",
        "\n",
        "    # the HP plot consists of three layers\n",
        "\n",
        "    # layer 1: backbone with solid line\n",
        "    ax.plot(\n",
        "        x, y,\n",
        "        color='cornflowerblue',\n",
        "        linewidth=3,\n",
        "    )\n",
        "    # layer 2: H as solid blue dots\n",
        "    ax.plot(\n",
        "        [h[0] for h in H_seq],\n",
        "        [h[1] for h in H_seq],\n",
        "        'o',\n",
        "        markersize=8,\n",
        "    )\n",
        "    # layer 3: P as hollow orange dots\n",
        "    ax.plot(\n",
        "        [p[0] for p in P_seq],\n",
        "        [p[1] for p in P_seq],\n",
        "        'o',\n",
        "        # fillstyle='none',\n",
        "        markersize=8,\n",
        "    )\n",
        "\n",
        "    # Show H-H bonds\n",
        "    ## Compute all pair distances for the bases in the configuration\n",
        "    coordinates = []\n",
        "    for i in range(len(labelled_conf)):\n",
        "        if labelled_conf[i][1] == 'H':\n",
        "            coordinates.append(labelled_conf[i][0])\n",
        "        else:\n",
        "            coordinates.append((-1000, 1000)) #To get rid of P's\n",
        "    distances = euclidean_distances(coordinates, coordinates)\n",
        "    ## We can extract the H-bonded pairs by looking at the upper-triangular (triu)\n",
        "    ## distance matrix, and taking those = 1, but ignore immediate neighbors (k=2).\n",
        "    bond_idx = np.where(np.triu(distances, k=2) == 1.0)    \n",
        "    for (x,y) in zip(*bond_idx):\n",
        "        xdata = [coordinates[x][0], coordinates[y][0]]\n",
        "        ydata = [coordinates[x][1], coordinates[y][1]]\n",
        "        backbone = mlines.Line2D(xdata, ydata, color='r', ls='-', zorder=1, linewidth=1.5)\n",
        "        ax.add_line(backbone)\n",
        "\n",
        "    fig.tight_layout(pad=0)\n",
        "\n",
        "    # import pyformulas as pf\n",
        "\n",
        "    # canvas = np.zeros((480,640))\n",
        "    # screen = pf.screen(canvas, 'Sinusoid')\n",
        "\n",
        "    plt.ion()\n",
        "    # based on canvas draw method\n",
        "    # If we haven't already shown or saved the plot, then we need to\n",
        "    # draw the figure first...\n",
        "    fig.canvas.draw()\n",
        "    # Now we can save it to a numpy array.\n",
        "    plt_data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
        "    # print(\"plt_data.shape, plt_data.dtype = \", plt_data.shape, plt_data.dtype)\n",
        "    # print(plt_data)\n",
        "    # define the closest square root\n",
        "    ns = np.ceil(np.sqrt(plt_data.shape[0]/3)).astype(int)\n",
        "    # print(\"ns = \", ns)\n",
        "    # print(\"fig.canvas.get_width_height() = \", fig.canvas.get_width_height())\n",
        "    # print(\"fig.canvas.get_width_height()[::-1] = \", fig.canvas.get_width_height()[::-1])\n",
        "    plt_data = plt_data.reshape((ns, ns) + (3,))\n",
        "    # print(\"plt_data.shape, plt_data.dtype = \", plt_data.shape, plt_data.dtype)\n",
        "    # print(plt_data)\n",
        "    # screen.update(plt_data)\n",
        "\n",
        "    # # based on savefig and buffer method\n",
        "    # io_buf = io.BytesIO()\n",
        "    # # Instead of saving the figure in png, one can use other format,\n",
        "    # # like raw or rgba and skip the cv2 decoding step.\n",
        "    # plt.savefig(io_buf, format='rgba', bbox_inches=0, pad_inches=0, dpi=30)\n",
        "    # # plt.savefig(io_buf, format='raw')\n",
        "    # io_buf.seek(0)\n",
        "    # print(\"fig.bbox.bounds = \", fig.bbox.bounds)\n",
        "    # buf_value = np.frombuffer(io_buf.getvalue(), dtype=np.uint8)\n",
        "    # print(\"buf_value.shape = \", buf_value.shape)\n",
        "    # # define the closest square root\n",
        "    # ns = np.ceil(np.sqrt(buf_value.shape[0])).astype(int)\n",
        "    # print(\"ns = \", ns)\n",
        "    # plt_data = np.reshape(buf_value,\n",
        "    #                  newshape=(ns, ns, -1))\n",
        "    # io_buf.close()\n",
        "    \n",
        "\n",
        "    # plt.savefig('CNN_plt_data.png', bbox_inches=0, pad_inches=0, dpi=30)\n",
        "    # plt.show()\n",
        "\n",
        "    # # close the plt window\n",
        "    plt.close()\n",
        "\n",
        "    return plt_data\n"
      ],
      "metadata": {
        "id": "6_Fw9q5tMl74"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import gym modules\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "\n",
        "import gym\n",
        "from gym import (spaces, utils, logger)\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "# from gym_lattice.envs.lattice2d_env_miranda_repo_2020Jul import Lattice2DEnv\n",
        "\n",
        "# from gym_lattice.envs.utils.obs_quaternary_to_base10 import obs_quaternary_to_base10\n",
        "# from gym_lattice.envs.utils.obs_quaternary_to_3N2 import obs_quaternary_to_3N2\n",
        "\n",
        "# import the hpsandbox util functions\n",
        "sys.path.append('../cod')\n",
        "\n",
        "\n",
        "# Over-write the miranda's default action to string dict\n",
        "ACTION_TO_STR = {\n",
        "    0: 'L',\n",
        "    1: 'F',\n",
        "    2: 'R'}\n",
        "\n",
        "\n",
        "class ThreeActionStateEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Inherits from Miranda's Lattice2DEnv (2D lattice environment)\n",
        "\n",
        "    Three actions (Left, Forward, Right)\n",
        "\n",
        "    Nov 25 2021 change to always DO NOT allow collision\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 seq,\n",
        "                 obs_output_mode=\"tuple\",\n",
        "                ):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        seq : str, must only consist of 'H' or 'P'\n",
        "            Sequence containing the polymer chain.\n",
        "        obs_output_mode : str, whether to output the observations\n",
        "            \"tuple\" --> as quaternary tuple of actions,\n",
        "            \"index_quaternary\" --> return the int of the decimal index\n",
        "            \"index_3N2\" --> return int of the 3N2 index\n",
        "        # for british museum use the state_E as reward, no need partial_reward\n",
        "        \"\"\"\n",
        "        self.seq = seq.upper()\n",
        "        self.obs_output_mode = obs_output_mode\n",
        "\n",
        "        # Initialize values\n",
        "        self.reset()\n",
        "\n",
        "        # customized 3actionStateEnv\n",
        "        print(\"=================Three Action State Env===============\\n\")\n",
        "\n",
        "        # Three Actions the seq must be longer than 2\n",
        "        if len(self.seq) <= 2:\n",
        "            return\n",
        "        # action_space is LFR actions\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "        # for obs space, [0] means no action taken yet\n",
        "        # [1,2,3] matches [L, F, R] actions\n",
        "        self.observation_space = spaces.Box(low=0, high=3,\n",
        "                                            # quaternary tuple len is N-2\n",
        "                                            shape=(len(self.seq)-2,),\n",
        "                                            dtype=int)\n",
        "        # NOTE: obs space of [2,2,3] means actions taken: F, F, R\n",
        "\n",
        "        # first_turn_left --> whether the first turn is a left\n",
        "        # after reset, this is default to False\n",
        "        self.first_turn_left = False\n",
        "\n",
        "        # print attributes and states for sanity check\n",
        "        print(\"ThreeActionStateEnv init with attributes:\")\n",
        "        print(\"self.seq = \", self.seq)\n",
        "        print(\"len(self.seq) = \", len(self.seq))\n",
        "        print(\"self.obs_output_mode = \", self.obs_output_mode)\n",
        "\n",
        "        print(\"self.state = \", self.state)\n",
        "        print(\"self.actions = \", self.actions)\n",
        "\n",
        "        print(\"self.action_space:\")\n",
        "        print(self.action_space)\n",
        "        print(\"self.observation_space:\")\n",
        "        print(self.observation_space)\n",
        "        print(\"self.observation_space.high, low:\")\n",
        "        print(self.observation_space.high)\n",
        "        print(self.observation_space.low)\n",
        "        print(\"self.observation_space.shape:\")\n",
        "        print(self.observation_space.shape)\n",
        "        print(\"self.observation_space.dtype, self.action_space.dtype\")\n",
        "        print(self.observation_space.dtype, self.action_space.dtype)\n",
        "\n",
        "        print(\"self.first_turn_left = \", self.first_turn_left)\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Overload the parent class' step()\n",
        "        \"\"\"\n",
        "        # print(\"\\n****************************************\")\n",
        "        # print(\"**************   NEW STEP  ***************\")\n",
        "        # print(\"****************************************\\n\")\n",
        "\n",
        "        # print(\"\\n***********step's action*********\")\n",
        "        # print(action, [\"Left\", \"Forward\", \"Right\"][action])\n",
        "\n",
        "        # print(\"\\n***********step's state*********\")\n",
        "        # print(self.state)\n",
        "\n",
        "        if not self.action_space.contains(action):\n",
        "            raise ValueError(\"%r (%s) invalid\" % (action, type(action)))\n",
        "\n",
        "        # print(\"self.first_turn_left = \", self.first_turn_left)\n",
        "        # if action is a turn, check whether first turn is already left\n",
        "        # action: 0,1,2 int\n",
        "        if (action != 1) and (self.first_turn_left is False):\n",
        "            # detect whether first turn is left (action 0) or right (action 2)\n",
        "            if action == 2:\n",
        "                action = 0\n",
        "            # print(\"Converted action = \", action)\n",
        "            self.first_turn_left = True\n",
        "            # print(\"-- after conversion, self.first_turn_left = \", self.first_turn_left)\n",
        "\n",
        "        self.last_action = action\n",
        "        is_trapped = False # Trap signal\n",
        "\n",
        "        # Obtain coordinate of previous polymer\n",
        "        # OrderedDict.keys() gives the coords\n",
        "        # p1 is the point two positions earlier\n",
        "        # p2 is the point one position earlier\n",
        "        # both p1 and p2 are tuples of (x,y)\n",
        "        p2 = list(self.state.keys())[-1]\n",
        "        p1 = list(self.state.keys())[-2]\n",
        "        # p3 is to-be-moved point == next_move\n",
        "        next_move = move_LFR_direction(\n",
        "            p1=p1,\n",
        "            p2=p2,\n",
        "            move_direction=action,\n",
        "        )\n",
        "        # print(\"\\n***********step's next_move*********\")\n",
        "        # print(next_move)\n",
        "        # Detects for collision or traps in the given coordinate\n",
        "        idx = len(self.state)\n",
        "        if next_move in self.state:\n",
        "            # print(\"next_move in self.state --> collision!\")\n",
        "            # Default does not allow collisions,\n",
        "            # ie, step() will retry until the next_move is not colliding\n",
        "            # send obs is None as signal for retry\n",
        "            return (None, None, False, {})\n",
        "        else:\n",
        "            # only append valid actions to action chain\n",
        "            self.actions.append(action)\n",
        "            try:\n",
        "                self.state.update({next_move : self.seq[idx]})\n",
        "            except IndexError:\n",
        "                logger.error('All molecules have been placed! Nothing can be added to the protein chain.')\n",
        "                raise\n",
        "\n",
        "            # NOTE: agent is only trapped WHEN THERE ARE STILL STEPS TO BE DONE!\n",
        "            if len(self.state) < len(self.seq):\n",
        "                if set(self._get_adjacent_coords(next_move).values()).issubset(self.state.keys()):\n",
        "                    # logger.warn('Your agent was trapped! Ending the episode.')\n",
        "                    is_trapped = True\n",
        "\n",
        "        # Set-up return values\n",
        "        obs = self.observe()\n",
        "        # print(\"\\n***********step's obs*********\")\n",
        "        # print(obs)\n",
        "\n",
        "        self.done = True if (len(self.state) == len(self.seq) or is_trapped) else False\n",
        "        reward = self._compute_reward()\n",
        "        info = {\n",
        "            'chain_length' : len(self.state),\n",
        "            'seq_length'   : len(self.seq),\n",
        "            'actions'      : [ACTION_TO_STR[i] for i in self.actions],\n",
        "            'is_trapped'   : is_trapped,\n",
        "            'state_chain'  : self.state,\n",
        "            \"first_turn_left\": self.first_turn_left,\n",
        "        }\n",
        "\n",
        "        return (obs, reward, self.done, info)\n",
        "\n",
        "\n",
        "    def observe(self):\n",
        "        \"\"\"\n",
        "        convert self.actions list to a tuple for base-4 system\n",
        "        0123 from actions (each action+1) --> 1234\n",
        "        The tuple returned is a base-4 quaternary number tuple:\n",
        "            0 = no action taken\n",
        "            1 = Left\n",
        "            2 = Forward\n",
        "            3 = Right\n",
        "        (3,2,2,0) = (R,F,F) for seq HPHPH\n",
        "\n",
        "        output:\n",
        "            NOTE: for NN compatibility, tuple is in fact np.array\n",
        "            either tuple or int, depending on\n",
        "            the self.obs_output_mode\n",
        "            \"tuple\" --> return the quaternary tuple\n",
        "            \"index_quaternary\" --> return the int of the decimal index\n",
        "            \"index_3N2\" --> return int of the 3N2 index\n",
        "        \"\"\"\n",
        "        # self.actions is list of 012 integers\n",
        "        action_chain = self.actions\n",
        "\n",
        "        # native obs space is [0,0,0,...,0]\n",
        "        # len of quaternary tuple is N-2\n",
        "        native_obs = np.zeros(shape=(len(self.seq)-2,), dtype=int)\n",
        "\n",
        "        # transfer the actions in action chain to\n",
        "        # the obs array (each action+1)\n",
        "        for i, item in enumerate(action_chain):\n",
        "            native_obs[i] = item+1\n",
        "\n",
        "        # for NN input, preserve the np array instead of tuple\n",
        "        quaternary_tuple = native_obs\n",
        "\n",
        "        # print(\"self.obs_output_mode = \", self.obs_output_mode)\n",
        "\n",
        "        if self.obs_output_mode == \"tuple\":\n",
        "            # in fact is a numpy array not a tuple for NN\n",
        "            return quaternary_tuple\n",
        "        # elif self.obs_output_mode == \"index_quaternary\":\n",
        "        #     return obs_quaternary_to_base10(quaternary_tuple)\n",
        "        # elif self.obs_output_mode == \"index_3N2\":\n",
        "        #     return obs_quaternary_to_3N2(quaternary_tuple)\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Inherits and overload parent class\n",
        "        Resets the environment\n",
        "        \"\"\"\n",
        "        self.actions = []\n",
        "\n",
        "        self.last_action = None\n",
        "        self.prev_reward = 0\n",
        "\n",
        "        # customized reset\n",
        "        # in miranda Jul2020 baseEnv and in 4actionState,\n",
        "        # the initial polymer is placed at origin\n",
        "        # for 3actionState, place the next polyer at (0,1)\n",
        "        self.state = OrderedDict(\n",
        "            {\n",
        "                (0, 0): self.seq[0],\n",
        "                (0, 1): self.seq[1],\n",
        "            }\n",
        "        )\n",
        "        self.done = len(self.seq) == 2\n",
        "        obs = self.observe()\n",
        "        # reset the first_turn_left for a new episode\n",
        "        self.first_turn_left = False\n",
        "\n",
        "        return obs\n",
        "\n",
        "\n",
        "    def render(self, mode='human', display_mode=\"draw\",\n",
        "               pause_t=0.0, save_fig=False, save_path=\"\",\n",
        "               score=2022, optima_idx=0):\n",
        "        \"\"\"\n",
        "        Use matplotlib to plot the grid\n",
        "        and the chain\n",
        "        \"\"\"\n",
        "        # print(\"\\n^^^^^^ Render called ^^^^^^\")\n",
        "\n",
        "        # outfile = StringIO() if mode == 'ansi' else sys.stdout\n",
        "\n",
        "        # print(\"render self.state: \", self.state)\n",
        "        # print(\"list(self.state): \", list(self.state.items()))\n",
        "        if mode == \"human\":\n",
        "            # matplotlib plot the conf\n",
        "            plot_HPSandbox_conf(\n",
        "                list(self.state.items()),\n",
        "                display_mode=display_mode,\n",
        "                pause_t=pause_t,\n",
        "                save_fig=save_fig,\n",
        "                save_path=save_path,\n",
        "                score=score,\n",
        "                optima_idx=optima_idx,\n",
        "                info={\n",
        "                    'chain_length' : len(self.state),\n",
        "                    'seq_length'   : len(self.seq),\n",
        "                    'actions'      : [ACTION_TO_STR[i] for i in self.actions],\n",
        "                },\n",
        "            )\n",
        "        # elif mode == \"CNN\":\n",
        "        #     # print(\"mode is CNN!\")\n",
        "        #     plt_data = output_CNN(\n",
        "        #         list(self.state.items()),\n",
        "        #         len(self.seq)\n",
        "        #     )\n",
        "        #     return plt_data\n",
        "\n",
        "        # Provide prompt for last action\n",
        "        # if self.last_action is not None:\n",
        "        #     outfile.write(\"Last Action:  ({})\\n\".format([\"Left\", \"Forward\", \"Right\"][self.last_action]))\n",
        "        # else:\n",
        "        #     outfile.write(\"\\n\")\n",
        "\n",
        "        # if mode != 'human':\n",
        "        #     return outfile\n",
        "\n",
        "        # print(\"****** Render Done ******\\n\")\n",
        "\n",
        "\n",
        "    def _get_adjacent_coords(self, coords):\n",
        "        \"\"\"Obtains all adjacent coordinates of the current position\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        coords : 2-tuple\n",
        "            Coordinates (X-y) of the current position\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dictionary\n",
        "            All adjacent coordinates\n",
        "        \"\"\"\n",
        "        x, y = coords\n",
        "        adjacent_coords = {\n",
        "            0 : (x - 1, y),\n",
        "            1 : (x, y - 1),\n",
        "            2 : (x, y + 1),\n",
        "            3 : (x + 1, y),\n",
        "        }\n",
        "\n",
        "        return adjacent_coords\n",
        "\n",
        "\n",
        "    def _compute_reward(self):\n",
        "        # new Sep19 reward in tuple (state_E, step_E, reward)\n",
        "        curr_reward = self._compute_free_energy(self.state)\n",
        "        state_E = curr_reward\n",
        "        step_E = curr_reward - self.prev_reward\n",
        "        self.prev_reward = curr_reward\n",
        "        reward = curr_reward if self.done else 0\n",
        "        # NOTE: let the RL algo decide how to use the state_E and penalty_per_node Sep23\n",
        "        # if is_trapped:\n",
        "        #     # punish trapped episode by clear-out to be -5 energy\n",
        "        #     state_E, step_E, reward = 5, 5, 5\n",
        "        return (-state_E, -step_E, -reward)\n",
        "\n",
        "\n",
        "    def _compute_free_energy(self, chain):\n",
        "        \"\"\"Computes the Gibbs free energy given the lattice's state\n",
        "\n",
        "        The free energy is only computed at the end of each episode. This\n",
        "        follow the same energy function given by Dill et. al.\n",
        "        [dill1989lattice]_\n",
        "\n",
        "        Recall that the goal is to find the configuration with the lowest\n",
        "        energy.\n",
        "\n",
        "        .. [dill1989lattice] Lau, K.F., Dill, K.A.: A lattice statistical\n",
        "        mechanics model of the conformational and se quence spaces of proteins.\n",
        "        Marcromolecules 22(10), 3986–3997 (1989)\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        chain : OrderedDict\n",
        "            Current chain in the lattice\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        int\n",
        "            Computed free energy\n",
        "        \"\"\"\n",
        "        # alternative way to compute number of HH bonds\n",
        "        use_triu_distance_mat = True\n",
        "        if use_triu_distance_mat:\n",
        "            dictlist = list(chain.items())\n",
        "            coordinates = []\n",
        "            for i in range(len(dictlist)):\n",
        "                if dictlist[i][1] == 'H':\n",
        "                    coordinates.append(dictlist[i][0])\n",
        "                else:\n",
        "                    coordinates.append((-1000, 1000)) #To get rid of P's\n",
        "            # print(\"coordinates matrix = \", coordinates)\n",
        "            distances = euclidean_distances(coordinates, coordinates)\n",
        "            # print(\"distances matrix = \", distances)\n",
        "            ## We can extract the H-bonded pairs by looking at the upper-triangular (triu)\n",
        "            ## distance matrix, and taking those = 1, but ignore immediate neighbors (k=2).\n",
        "            bond_idx = np.where(np.triu(distances, k=2) == 1.0)\n",
        "            \"\"\"\n",
        "            bond_idx is a tuple\n",
        "            for m HH bonds ->\n",
        "            (array([x1, x2, ..., x_m]), array([y1, y2, ..., y_m]))\n",
        "            \"\"\"\n",
        "            # print(\"bond_idx = \", bond_idx)\n",
        "            # print(\"len(bond_idx[0]) = \", len(bond_idx[0]))\n",
        "            reward = -1 * len(bond_idx[0])\n",
        "            return int(reward)\n",
        "\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        \"\"\"\n",
        "        seed the gym env\n",
        "        NOTE: this umbrella seed() will seed the end globally\n",
        "        it will seed:\n",
        "            action_space\n",
        "            np random (for uniform to_exploit)\n",
        "        \"\"\"\n",
        "        self.np_random, seed = utils.seeding.np_random(seed)\n",
        "\n",
        "        # NOTE: spaces sample use separate random number generator\n",
        "        # that lives in gym.spaces.prng. If you want action / observation\n",
        "        # space to sample deterministically you will need to seed separately\n",
        "        self.action_space.seed(seed)\n",
        "        # NOTE: agent also uses randomness, need to seed that separately\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        return [seed]\n",
        "from gym.envs.registration import register\n",
        "\n",
        "register(\n",
        "    id='Lattice2D-3actionStateEnv-v0',\n",
        "    entry_point='ThreeActionStateEnv',\n",
        ")\n"
      ],
      "metadata": {
        "id": "Q37DLhk_LxB3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the annealing schedule\n",
        "Plot_Anneal_Schedule(\n",
        "    num_episodes,\n",
        "    min_exploration_rate,\n",
        "    max_exploration_rate,\n",
        "    mode=display_mode,\n",
        "    save_path=save_path,\n",
        "    warmRestart=warmRestart,\n",
        "    decay_mode=decay_mode,\n",
        "    num_restarts=num_restarts,\n",
        "    exploration_decay_rate=exploration_decay_rate,\n",
        "    start_decay=start_decay,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Nov30 2021 add one more column of step_E\n",
        "hp_depth = 2  # {H,P} binary alphabet\n",
        "action_depth = 4  # 0,1,2,3 in observation_box\n",
        "energy_depth = 0  # state_E and step_E\n",
        "# one hot the HP seq\n",
        "seq_bin_arr = np.asarray([1 if x == 'H' else 0 for x in seq])\n",
        "seq_one_hot = F.one_hot(torch.from_numpy(seq_bin_arr), num_classes=hp_depth)\n",
        "seq_one_hot = seq_one_hot.numpy()\n",
        "# print(f\"seq({seq})'s one_hot = \")\n",
        "# print(seq_one_hot)\n",
        "init_HP_len = 2  # initial two HP units placed\n",
        "first_two_actions = np.zeros((init_HP_len,), dtype=int)\n",
        "\n",
        "def one_hot_state(state_arr, seq_one_hot, action_depth):\n",
        "                  # state_E_col, step_E_col):\n",
        "    \"\"\"\n",
        "    for NN:\n",
        "    \"one-hot\" --> return the one-hot version of the quaternary tuple\n",
        "    \"\"\"\n",
        "    state_arr = np.concatenate((first_two_actions, state_arr))\n",
        "    # print(\"after catting first_two_actions, state_arr = \", state_arr, state_arr.dtype, state_arr.shape)\n",
        "    state_arr = F.one_hot(torch.from_numpy(state_arr), num_classes=action_depth)\n",
        "    state_arr = state_arr.numpy()  # q.sample_action expects numpy arr\n",
        "    # print(\"one-hot first_two_actions catted state = \")\n",
        "    # print(state_arr)\n",
        "    state_arr = np.concatenate((\n",
        "        # state_E_col,\n",
        "        # step_E_col,\n",
        "        state_arr,\n",
        "        seq_one_hot), axis=1)\n",
        "    # print(\"state_arr concat with seq_one_hot, state_E_col, step_E_col =\")\n",
        "    # print(state_arr)\n",
        "    return state_arr\n",
        "\n",
        "# environment IDs\n",
        "# env_id=\"gym_lattice:Lattice2D-4actionStateEnv-v0\"\n",
        "env_id = \":Lattice2D-3actionStateEnv-v0\"\n",
        "\n",
        "if env_id == \":Lattice2D-4actionStateEnv-v0\":\n",
        "    # observation output mode:\n",
        "    # 1. \"tuple\"\n",
        "    # 2. \"index_pental\"\n",
        "    # 3. \"index_4N3\"\n",
        "    obs_output_mode = \"index_4N3\"\n",
        "elif env_id == \":Lattice2D-3actionStateEnv-v0\":\n",
        "    # observation output mode:\n",
        "    # 1. \"tuple\"\n",
        "    # 2. \"index_quaternary\"\n",
        "    # 3. \"index_3N2\"\n",
        "    obs_output_mode = \"tuple\"\n",
        "env_id = \"__main__\"+env_id\n",
        "# NOTE: partial_reward Sep15 changed to delta of curr-prev rewards\n",
        "\n",
        "# env = gym.make(id=\"gym_lattice:Lattice2D-miranda2020Jul-v1\", seq=seq)\n",
        "env = ThreeActionStateEnv(seq,obs_output_mode)\n",
        "\n",
        "# reproducible environment and action spaces, do not change lines 6-11 here (tools > settings > editor > show line numbers)\n",
        "torch.manual_seed(seed)\n",
        "env.seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "env.action_space.seed(seed)\n",
        "\n",
        "# initial state/observation\n",
        "# NOTE: env.state != state here\n",
        "# env.state is actually the chain of OrderedDict([((0, 0), 'H')])\n",
        "# the state here actually refers to the observation!\n",
        "initial_state = env.reset()\n",
        "\n",
        "print(\"initial state/obs:\")\n",
        "print(initial_state)\n",
        "\n",
        "# Get number of actions from gym action space\n",
        "n_actions = env.action_space.n\n",
        "print(\"n_actions = \", n_actions)\n",
        "\n",
        "# choice of network for DRL = \"FCN_QNet, RNN_LSTM_onlyLastHidden, BRNN...\"\n",
        "network_choice = \"FCN_QNet\"\n",
        "row_width = action_depth + hp_depth + energy_depth\n",
        "col_length = env.observation_space.shape[0] + init_HP_len\n",
        "\n",
        "if network_choice == \"FCN_QNet\":\n",
        "    # FCN_QNet() takes two params: insize and outsize\n",
        "    # insize ==> input size == size of the observation space\n",
        "    # insize is flattened obs\n",
        "    insize = col_length * row_width\n",
        "    print(\"FCN_QNet insize = \", insize)\n",
        "    # outsize ==> output size == number of actions\n",
        "    print(\"FCN_QNet outsize = \", n_actions)\n",
        "    q = FCN_QNet(insize, n_actions).to(device)\n",
        "    q_target = FCN_QNet(insize, n_actions).to(device)\n",
        "elif network_choice == \"RNN_LSTM_onlyLastHidden\":\n",
        "    # config for RNN\n",
        "    input_size = row_width\n",
        "    # number of nodes in the hidden layers\n",
        "    hidden_size = 256\n",
        "    num_layers = 2\n",
        "\n",
        "    print(\"RNN_LSTM_onlyLastHidden with:\")\n",
        "    print(f\"inputs_size={input_size} hidden_size={hidden_size} num_layers={num_layers} num_classes={n_actions}\")\n",
        "    # Initialize network (try out just using simple RNN, or GRU, and then compare with LSTM)\n",
        "    q = RNN_LSTM_onlyLastHidden(input_size, hidden_size, num_layers, n_actions).to(device)\n",
        "    q_target = RNN_LSTM_onlyLastHidden(input_size, hidden_size, num_layers, n_actions).to(device)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
        "\n",
        "memory = ReplayBuffer(buffer_limit)\n",
        "# load pre-populated Replay Buffer with good early-stopped and r_max\n",
        "# TODO: memory.load(f'./xxx.pkl')\n",
        "\n",
        "# monitor GPU usage\n",
        "print(\"torch.cuda.is_available() = \", torch.cuda.is_available())\n",
        "print(\"device = \", device)\n",
        "# Additional Info when using cuda\n",
        "# https://newbedev.com/how-to-check-if-pytorch-is-using-the-gpu\n",
        "if device.type == 'cuda':\n",
        "    # Get the name of the current GPU\n",
        "    print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "    # print('Memory Usage:')\n",
        "    # print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    # print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
        "\n",
        "# Inspect NN state_dict in pytorch\n",
        "# Print model's state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in q.state_dict():\n",
        "    print(param_tensor, \"\\t\", q.state_dict()[param_tensor].size())\n",
        "\n",
        "# Print optimizer's state_dict\n",
        "print(\"Optimizer's state_dict:\")\n",
        "for var_name in optimizer.state_dict():\n",
        "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
        "\n",
        "# time the experiment\n",
        "\n",
        "\n",
        "for n_episode in range(num_episodes):\n",
        "    # print(\"\\nEpisode: \", n_episode)\n",
        "\n",
        "    # only render the game every once a while\n",
        "    if (n_episode == 0) or ((n_episode+1) % show_every == 0):\n",
        "        if display_mode == \"show\":\n",
        "            render = True  # can enable render for debugging\n",
        "        elif display_mode == \"save\":\n",
        "            render = False\n",
        "    else:\n",
        "        render = False\n",
        "\n",
        "    # epsilon = max(min_exploration_rate, max_exploration_rate - exploration_decay_rate*(n_episode/200)) # linear annealing\n",
        "    if decay_mode == \"cosine\":\n",
        "        epsilon = CosineAnnealingSchedule(\n",
        "            n_episode,\n",
        "            num_episodes,\n",
        "            min_exploration_rate,\n",
        "            max_exploration_rate,\n",
        "            warmRestart=warmRestart,\n",
        "            num_restarts=num_restarts,\n",
        "        )\n",
        "    elif decay_mode == \"exponential\":\n",
        "        epsilon = ExponentialDecay(\n",
        "            n_episode,\n",
        "            num_episodes,\n",
        "            min_exploration_rate,\n",
        "            max_exploration_rate,\n",
        "            exploration_decay_rate=exploration_decay_rate,\n",
        "            start_decay=start_decay,\n",
        "        )\n",
        "    elif decay_mode == \"linear\":\n",
        "        epsilon = LinearDecay(\n",
        "            n_episode,\n",
        "            num_episodes,\n",
        "            min_exploration_rate,\n",
        "            max_exploration_rate,\n",
        "            start_decay=start_decay,\n",
        "        )\n",
        "\n",
        "    # reset the environment\n",
        "    # Initialize the environment and state\n",
        "    s = env.reset()\n",
        "    # print(\"s = \", s, s.dtype, s.shape)\n",
        "    # print(\"torch.from_numpy(s) = \", torch.from_numpy(s))\n",
        "\n",
        "    \"\"\"\n",
        "    for NN:\n",
        "    \"one-hot\" --> return the one-hot version of the quaternary tuple\n",
        "    \"\"\"\n",
        "    # revert state_E and step_E cols Dec03 2021\n",
        "    # # column of state_E and column of step_e\n",
        "    # state_E_col = np.zeros((col_length, 1))\n",
        "    # step_E_col = np.zeros((col_length, 1))\n",
        "    s = one_hot_state(s, seq_one_hot, action_depth)\n",
        "                      # state_E_col, step_E_col)\n",
        "    # print(\"one-hot initial_state = \")\n",
        "    # print(s)\n",
        "\n",
        "    done = False\n",
        "    score = 0.0\n",
        "\n",
        "    # early stopped due to S_B O and E?\n",
        "    early_stopped = False\n",
        "    # whether to avoid F in the next step?\n",
        "    avoid_F = False\n",
        "\n",
        "    for step in range(max_steps_per_episode):\n",
        "        # print(f\"--- Ep{n_episode} new step-{step}\")\n",
        "        # sample the action from Q\n",
        "        # convert the given state to torch\n",
        "        # epsilon is the chance to explore\n",
        "\n",
        "        # unsqueeze(0) adds a dimension at 0th for batch=1\n",
        "        # i.e. adds a batch dimension\n",
        "        a = q.sample_action(torch.from_numpy(s).float().unsqueeze(0), epsilon)\n",
        "        # print('---> action = ', a)\n",
        "\n",
        "        # take the step and get the returned observation s_prime\n",
        "        s_prime, r, done, info = env.step(a)\n",
        "        # print(f\"s_prime: {s_prime}, reward: {r}, done: {done}, info: {info}\")\n",
        "\n",
        "        # if do not allow for collision, ie. no collision penalty\n",
        "        # new_state returned from step() will be None\n",
        "        while s_prime is None:\n",
        "            # retry until action is not colliding\n",
        "            # print(\"retry sample another action...\")\n",
        "            a = ((a + 1) % 3)\n",
        "            # print(\"retried action = \", a)\n",
        "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
        "            s_prime, r, done, info = env.step(a)\n",
        "            # print(f\"s_prime: {s_prime}, reward: {r}, done: {done}, info: {info}\")\n",
        "\n",
        "        # Only keep first turn of Left\n",
        "        # internal 3actionStateEnv self.last_action updated\n",
        "        a = env.last_action\n",
        "        # print(\"internal 3actionStateEnv last_action = \", a)\n",
        "\n",
        "        # Sep19 reward returned from Env is a tuple of (state_E, step_E, reward)\n",
        "        # print(\"reward tuple = \", r)\n",
        "        (state_E, step_E, reward) = r\n",
        "        # print(\"state_E, step_E, reward = \", state_E, step_E, reward)\n",
        "\n",
        "        \"\"\"\n",
        "        for NN:\n",
        "            \"one-hot\" --> return the one-hot version of the quaternary tuple\n",
        "        \"\"\"\n",
        "        # state_E_col[step + init_HP_len] = state_E / OPT_S\n",
        "        # step_E_col[step + init_HP_len] = step_E / OPT_S\n",
        "        s_prime = one_hot_state(s_prime, seq_one_hot, action_depth)\n",
        "                                # state_E_col, step_E_col)\n",
        "        # print(\"one-hot s_prime = \")\n",
        "        # print(s_prime)\n",
        "\n",
        "        if info[\"is_trapped\"]:\n",
        "            # print('info[\"is_trapped\"] = ', info[\"is_trapped\"])\n",
        "            # reward = -(OPT_S - state_E)  # offset by state_E\n",
        "            # Jan 2022 discover that trap penalty is interfering\n",
        "            reward = state_E\n",
        "            # print(\"adjusted trapped reward = \", reward)\n",
        "\n",
        "\n",
        "        # NOTE: MUST ENSURE THE REWARD IS FINALIZED BEFORE FEEDING TO RL ALGO!!\n",
        "\n",
        "        r = reward\n",
        "\n",
        "        # NOTE: done_mask is for when you get the end of a run,\n",
        "        # then is no future reward, so we mask it with done_mask\n",
        "        done_mask = 0.0 if done else 1.0\n",
        "        # put the sampled state-action-reward-stateAfterwards\n",
        "        # NOTE: here r is divided by 100.0? Undo the 100.0 Sep04 2021\n",
        "        # NOTE: priorize experience that are\n",
        "        # 1. not trapped (r = -1)\n",
        "        # 2. not early-stopped\n",
        "        # 3.\n",
        "        memory.put((s,a,r,s_prime, done_mask))\n",
        "        s = s_prime\n",
        "\n",
        "        # Add new reward\n",
        "        # NOTE: Sep15 update partial_reward to be delta instead of progress*curr_reward\n",
        "        # NOTE: Sep19 update reward to be a tuple, and reward is 0 until done\n",
        "        score += r\n",
        "\n",
        "      \n",
        "        # clear_output(wait=True)\n",
        "        # check if the last action ended the episode\n",
        "        if done:\n",
        "            # print(\"Episode finished! Actions: {}\".format(info['actions']))\n",
        "            # if done and used up all actions, pass\n",
        "            # if done but trapped, zero out the reward\n",
        "            if len(info['actions']) == (len(seq) - 2):\n",
        "                # print(\"Complete: used up all actions!\")\n",
        "                pass\n",
        "            else:\n",
        "                if use_early_stop and early_stopped:\n",
        "                    # print(\"EARLY STOPPED\")\n",
        "                    num_early_stopped += 1\n",
        "                else:\n",
        "                    # otherwise it means the actions result in trapped episode\n",
        "                    # print(\"TRAPPED!\")\n",
        "                    num_trapped += 1\n",
        "            break\n",
        "\n",
        "    # eventually if memory is big enough, we start running the training loop\n",
        "    # start training after 2000 (for eg) can get a wider distribution\n",
        "    # print(\"memory.size() = \", memory.size())\n",
        "    if memory.size()>mem_start_train:\n",
        "        train(q, q_target, memory, optimizer)\n",
        "\n",
        "    # Update the target network, copying all weights and biases in DQN\n",
        "    if n_episode % TARGET_UPDATE == 0:\n",
        "        q_target.load_state_dict(q.state_dict())\n",
        "\n",
        "    # print(\"score = \", score)\n",
        "    # inspect local optima for non-ES spisode scores\n",
        "    # Add current episode reward to total rewards list\n",
        "    rewards_all_episodes[n_episode] = score\n",
        "    # update max reward found so far\n",
        "    if score > reward_max:\n",
        "        print(\"found new highest reward = \", score)\n",
        "        reward_max = score\n",
        "        env.render(\n",
        "            display_mode=display_mode,\n",
        "            save_fig=save_fig,\n",
        "            save_path=save_path,\n",
        "            score=score,\n",
        "        )\n",
        "\n",
        "    if (n_episode == 0) or ((n_episode+1) % show_every == 0):\n",
        "        print(\"Episode {}, score: {:.1f}, epsilon: {:.2f}, reward_max: {}\".format(\n",
        "            n_episode,\n",
        "            score,\n",
        "            epsilon,\n",
        "            reward_max,\n",
        "        ))\n",
        "        print(f\"\\ts_prime: {s_prime[:3], s_prime.shape}, reward: {r}, done: {done}, info: {info}\")\n",
        "    # move on to the next episode\n",
        "\n",
        "print('Complete')\n",
        "# for time records\n",
        "# Save the ReplayMemory\n",
        "# TODO: later memory.save(f'{save_path}{config_str}-replaybuffer.pkl')\n",
        "\n",
        "# Save the pytorch model\n",
        "# Saving & Loading Model for Inference\n",
        "# Save/Load state_dict (Recommended)\n",
        "\n",
        "# ***** plot the stats and save in save_path *****\n",
        "\n",
        "plot_moving_avg(rewards_all_episodes, mode=display_mode, save_path=save_path)\n",
        "log_rewards_frequency(rewards_all_episodes)\n",
        "plot_rewards_histogram(\n",
        "    rewards_all_episodes,\n",
        "    mode=display_mode,\n",
        "    save_path=save_path,\n",
        "    config_str=config_str,\n",
        ")\n",
        "plot_print_rewards_stats(\n",
        "    rewards_all_episodes,\n",
        "    show_every,\n",
        "    mode=display_mode,\n",
        "    save_path=save_path,\n",
        ")\n",
        "\n",
        "env.close()\n",
        "\n",
        "\n",
        "# # record the performance to a mega stats csv\n",
        "# with open(f\"./HP{len(seq)}-{base_dir}-stats.csv\", \"a+\") as csv_file:\n",
        "#     stats_writer = csv.writer(\n",
        "#         csv_file,\n",
        "#         delimiter=',',\n",
        "#         quotechar='\"',\n",
        "#         quoting=csv.QUOTE_MINIMAL\n",
        "#     )\n",
        "#     stats_writer.writerow([seq, seed, reward_max])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QBuWGO5oNHpc",
        "outputId": "2f8eb249-6447-4c48-c6d1-2199040504d1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "warmRestart =  True\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================Three Action State Env===============\n",
            "\n",
            "ThreeActionStateEnv init with attributes:\n",
            "self.seq =  HHPPHH\n",
            "len(self.seq) =  6\n",
            "self.obs_output_mode =  tuple\n",
            "self.state =  OrderedDict([((0, 0), 'H'), ((0, 1), 'H')])\n",
            "self.actions =  []\n",
            "self.action_space:\n",
            "Discrete(3)\n",
            "self.observation_space:\n",
            "Box(0, 3, (4,), int64)\n",
            "self.observation_space.high, low:\n",
            "[3 3 3 3]\n",
            "[0 0 0 0]\n",
            "self.observation_space.shape:\n",
            "(4,)\n",
            "self.observation_space.dtype, self.action_space.dtype\n",
            "int64 int64\n",
            "self.first_turn_left =  False\n",
            "initial state/obs:\n",
            "[0 0 0 0]\n",
            "n_actions =  3\n",
            "FCN_QNet insize =  36\n",
            "FCN_QNet outsize =  3\n",
            "torch.cuda.is_available() =  True\n",
            "device =  cuda\n",
            "NVIDIA A100-SXM4-40GB\n",
            "Model's state_dict:\n",
            "fc1.weight \t torch.Size([256, 36])\n",
            "fc1.bias \t torch.Size([256])\n",
            "fc2.weight \t torch.Size([84, 256])\n",
            "fc2.bias \t torch.Size([84])\n",
            "fc3.weight \t torch.Size([3, 84])\n",
            "fc3.bias \t torch.Size([3])\n",
            "Optimizer's state_dict:\n",
            "state \t {}\n",
            "param_groups \t [{'lr': 0.0005, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5]}]\n",
            "Episode 0, score: 0.0, epsilon: 1.00, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 9, score: 0.0, epsilon: 1.00, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 2), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 19, score: 0.0, epsilon: 0.99, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')]), 'first_turn_left': True}\n",
            "Episode 29, score: 0.0, epsilon: 0.99, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 39, score: 0.0, epsilon: 0.98, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')]), 'first_turn_left': True}\n",
            "Episode 49, score: 0.0, epsilon: 0.98, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 2), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 59, score: 0.0, epsilon: 0.97, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-3, 1), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 69, score: 0.0, epsilon: 0.97, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')]), 'first_turn_left': True}\n",
            "Episode 79, score: 0.0, epsilon: 0.96, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 89, score: 0.0, epsilon: 0.96, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 99, score: 0.0, epsilon: 0.95, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 109, score: 1.0, epsilon: 0.95, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((0, 2), 'H'), ((1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 119, score: 2.0, epsilon: 0.94, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 129, score: 1.0, epsilon: 0.94, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 139, score: 0.0, epsilon: 0.93, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-2, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 149, score: 0.0, epsilon: 0.93, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 2), 'H'), ((-1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 159, score: 0.0, epsilon: 0.92, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 169, score: 0.0, epsilon: 0.92, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 179, score: 0.0, epsilon: 0.92, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 189, score: 0.0, epsilon: 0.91, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 199, score: 0.0, epsilon: 0.91, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 209, score: 1.0, epsilon: 0.90, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 219, score: 0.0, epsilon: 0.90, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-2, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 229, score: 0.0, epsilon: 0.89, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-3, 1), 'H'), ((-3, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 239, score: 0.0, epsilon: 0.89, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 249, score: 0.0, epsilon: 0.88, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 259, score: 0.0, epsilon: 0.88, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-3, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 269, score: 0.0, epsilon: 0.88, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 279, score: 0.0, epsilon: 0.87, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 2), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 289, score: 0.0, epsilon: 0.87, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')]), 'first_turn_left': True}\n",
            "Episode 299, score: 1.0, epsilon: 0.86, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 0), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 309, score: 1.0, epsilon: 0.86, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 319, score: 0.0, epsilon: 0.85, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 329, score: 0.0, epsilon: 0.85, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')]), 'first_turn_left': True}\n",
            "Episode 339, score: 1.0, epsilon: 0.85, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((0, 2), 'H'), ((1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 349, score: 0.0, epsilon: 0.84, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 359, score: 0.0, epsilon: 0.84, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 369, score: 0.0, epsilon: 0.83, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-3, 1), 'H'), ((-3, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 379, score: 1.0, epsilon: 0.83, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 389, score: 0.0, epsilon: 0.83, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 399, score: 2.0, epsilon: 0.82, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 409, score: 0.0, epsilon: 0.82, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-3, 1), 'H'), ((-3, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 419, score: 0.0, epsilon: 0.81, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 429, score: 1.0, epsilon: 0.81, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 0), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 439, score: 1.0, epsilon: 0.80, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((0, 2), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 449, score: 1.0, epsilon: 0.80, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((0, 2), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 459, score: 0.0, epsilon: 0.80, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 469, score: 0.0, epsilon: 0.79, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 479, score: 0.0, epsilon: 0.79, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 489, score: 0.0, epsilon: 0.79, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 499, score: 0.0, epsilon: 0.78, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 509, score: 2.0, epsilon: 0.78, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 519, score: 0.0, epsilon: 0.77, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 529, score: 0.0, epsilon: 0.77, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 539, score: 0.0, epsilon: 0.77, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 549, score: 0.0, epsilon: 0.76, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 559, score: 2.0, epsilon: 0.76, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 569, score: 0.0, epsilon: 0.75, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 579, score: 0.0, epsilon: 0.75, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-2, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 589, score: 0.0, epsilon: 0.75, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 599, score: 0.0, epsilon: 0.74, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 2), 'H'), ((-1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 609, score: 1.0, epsilon: 0.74, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 619, score: 2.0, epsilon: 0.74, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 629, score: 0.0, epsilon: 0.73, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 0), 'H'), ((-2, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 639, score: 0.0, epsilon: 0.73, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 649, score: 0.0, epsilon: 0.73, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 659, score: 0.0, epsilon: 0.72, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-2, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 669, score: 1.0, epsilon: 0.72, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 679, score: 2.0, epsilon: 0.72, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 689, score: 0.0, epsilon: 0.71, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 699, score: 0.0, epsilon: 0.71, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-2, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 709, score: 0.0, epsilon: 0.70, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 719, score: 2.0, epsilon: 0.70, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 729, score: 0.0, epsilon: 0.70, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 739, score: 0.0, epsilon: 0.69, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-3, 1), 'H'), ((-4, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 749, score: 0.0, epsilon: 0.69, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 759, score: 0.0, epsilon: 0.69, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 769, score: 0.0, epsilon: 0.68, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 779, score: 0.0, epsilon: 0.68, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 789, score: 2.0, epsilon: 0.68, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 799, score: 0.0, epsilon: 0.67, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 809, score: 0.0, epsilon: 0.67, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 819, score: 1.0, epsilon: 0.67, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 829, score: 1.0, epsilon: 0.66, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 839, score: 0.0, epsilon: 0.66, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 849, score: 0.0, epsilon: 0.66, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')]), 'first_turn_left': True}\n",
            "Episode 859, score: 0.0, epsilon: 0.65, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 869, score: 0.0, epsilon: 0.65, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-2, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 879, score: 1.0, epsilon: 0.65, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((0, 2), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 889, score: 0.0, epsilon: 0.64, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 0), 'H'), ((-3, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 899, score: 0.0, epsilon: 0.64, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')]), 'first_turn_left': True}\n",
            "Episode 909, score: 2.0, epsilon: 0.64, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 919, score: 0.0, epsilon: 0.64, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 929, score: 0.0, epsilon: 0.63, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 939, score: 1.0, epsilon: 0.63, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 949, score: 1.0, epsilon: 0.63, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 959, score: 1.0, epsilon: 0.62, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 969, score: 0.0, epsilon: 0.62, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 979, score: 2.0, epsilon: 0.62, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 989, score: 2.0, epsilon: 0.61, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 999, score: 1.0, epsilon: 0.61, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1009, score: 0.0, epsilon: 0.61, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1019, score: 0.0, epsilon: 0.60, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 1029, score: 1.0, epsilon: 0.60, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1039, score: 1.0, epsilon: 0.60, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1049, score: 2.0, epsilon: 0.60, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1059, score: 0.0, epsilon: 0.59, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 1069, score: 1.0, epsilon: 0.59, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1079, score: 0.0, epsilon: 0.59, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1089, score: 1.0, epsilon: 0.58, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1099, score: 2.0, epsilon: 0.58, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1109, score: 2.0, epsilon: 0.58, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1119, score: 0.0, epsilon: 0.58, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-2, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1129, score: 0.0, epsilon: 0.57, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 1139, score: 0.0, epsilon: 0.57, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')]), 'first_turn_left': True}\n",
            "Episode 1149, score: 1.0, epsilon: 0.57, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 0), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1159, score: 1.0, epsilon: 0.56, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1169, score: 0.0, epsilon: 0.56, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 1179, score: 0.0, epsilon: 0.56, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1189, score: 0.0, epsilon: 0.56, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 1199, score: 1.0, epsilon: 0.55, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1209, score: 0.0, epsilon: 0.55, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-2, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1219, score: 0.0, epsilon: 0.55, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-3, 1), 'H'), ((-3, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1229, score: 0.0, epsilon: 0.55, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 1239, score: 2.0, epsilon: 0.54, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1249, score: 0.0, epsilon: 0.54, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 1259, score: 1.0, epsilon: 0.54, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1269, score: 0.0, epsilon: 0.53, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 1279, score: 2.0, epsilon: 0.53, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1289, score: 0.0, epsilon: 0.53, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-3, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1299, score: 1.0, epsilon: 0.53, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1309, score: 2.0, epsilon: 0.52, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1319, score: 0.0, epsilon: 0.52, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 1329, score: 2.0, epsilon: 0.52, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1339, score: 1.0, epsilon: 0.52, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 0), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1349, score: 0.0, epsilon: 0.51, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1359, score: 2.0, epsilon: 0.51, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1369, score: 0.0, epsilon: 0.51, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 1379, score: 0.0, epsilon: 0.51, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((0, 4), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 1389, score: 0.0, epsilon: 0.50, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')]), 'first_turn_left': True}\n",
            "Episode 1399, score: 2.0, epsilon: 0.50, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1409, score: 2.0, epsilon: 0.50, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1419, score: 2.0, epsilon: 0.50, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1429, score: 1.0, epsilon: 0.49, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((0, 2), 'H'), ((1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 1439, score: 0.0, epsilon: 0.49, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-3, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1449, score: 0.0, epsilon: 0.49, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 1459, score: 0.0, epsilon: 0.49, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-3, 1), 'H'), ((-4, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1469, score: 0.0, epsilon: 0.48, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 1479, score: 1.0, epsilon: 0.48, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1489, score: 0.0, epsilon: 0.48, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 1499, score: 1.0, epsilon: 0.48, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((0, 2), 'H'), ((1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 1509, score: 0.0, epsilon: 0.48, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 1519, score: 0.0, epsilon: 0.47, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 1529, score: 1.0, epsilon: 0.47, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1539, score: 1.0, epsilon: 0.47, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1549, score: 2.0, epsilon: 0.47, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1559, score: 1.0, epsilon: 0.46, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 0), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1569, score: 1.0, epsilon: 0.46, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((0, 2), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 1579, score: 2.0, epsilon: 0.46, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1589, score: 1.0, epsilon: 0.46, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1599, score: 0.0, epsilon: 0.46, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1609, score: 0.0, epsilon: 0.45, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 1619, score: 0.0, epsilon: 0.45, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 1629, score: 0.0, epsilon: 0.45, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 0), 'H'), ((-3, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1639, score: 0.0, epsilon: 0.45, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')]), 'first_turn_left': True}\n",
            "Episode 1649, score: 0.0, epsilon: 0.44, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((0, 4), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 1659, score: 0.0, epsilon: 0.44, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-2, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1669, score: 0.0, epsilon: 0.44, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-2, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1679, score: 0.0, epsilon: 0.44, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((0, 4), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 1689, score: 2.0, epsilon: 0.44, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1699, score: 2.0, epsilon: 0.43, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1709, score: 2.0, epsilon: 0.43, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1719, score: 1.0, epsilon: 0.43, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((0, 2), 'H'), ((1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 1729, score: 1.0, epsilon: 0.43, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1739, score: 1.0, epsilon: 0.42, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((0, 2), 'H'), ((1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 1749, score: 1.0, epsilon: 0.42, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1759, score: 2.0, epsilon: 0.42, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1769, score: 0.0, epsilon: 0.42, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 1779, score: 0.0, epsilon: 0.42, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-3, 1), 'H'), ((-3, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1789, score: 2.0, epsilon: 0.41, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1799, score: 2.0, epsilon: 0.41, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1809, score: 0.0, epsilon: 0.41, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 1819, score: 2.0, epsilon: 0.41, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1829, score: 2.0, epsilon: 0.41, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1839, score: 0.0, epsilon: 0.40, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 1849, score: 1.0, epsilon: 0.40, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((0, 2), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 1859, score: 0.0, epsilon: 0.40, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((0, 4), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 1869, score: 2.0, epsilon: 0.40, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1879, score: 0.0, epsilon: 0.40, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 1889, score: 2.0, epsilon: 0.39, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1899, score: 1.0, epsilon: 0.39, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((0, 2), 'H'), ((1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 1909, score: 2.0, epsilon: 0.39, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1919, score: 2.0, epsilon: 0.39, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1929, score: 0.0, epsilon: 0.39, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1939, score: 0.0, epsilon: 0.39, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 1949, score: 2.0, epsilon: 0.38, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1959, score: 2.0, epsilon: 0.38, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1969, score: 2.0, epsilon: 0.38, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 1979, score: 1.0, epsilon: 0.38, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((0, 2), 'H'), ((1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 1989, score: 1.0, epsilon: 0.38, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 1999, score: 0.0, epsilon: 0.37, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 2009, score: 0.0, epsilon: 0.37, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((0, 4), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 2019, score: 1.0, epsilon: 0.37, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2029, score: 2.0, epsilon: 0.37, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2039, score: 1.0, epsilon: 0.37, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2049, score: 2.0, epsilon: 0.37, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2059, score: 0.0, epsilon: 0.36, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 2069, score: 0.0, epsilon: 0.36, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2079, score: 2.0, epsilon: 0.36, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2089, score: 2.0, epsilon: 0.36, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2099, score: 2.0, epsilon: 0.36, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2109, score: 2.0, epsilon: 0.35, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2119, score: 1.0, epsilon: 0.35, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 0), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2129, score: 2.0, epsilon: 0.35, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2139, score: 2.0, epsilon: 0.35, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2149, score: 1.0, epsilon: 0.35, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2159, score: 2.0, epsilon: 0.35, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2169, score: 1.0, epsilon: 0.34, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 0), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2179, score: 2.0, epsilon: 0.34, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2189, score: 1.0, epsilon: 0.34, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2199, score: 2.0, epsilon: 0.34, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2209, score: 0.0, epsilon: 0.34, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 2219, score: 1.0, epsilon: 0.34, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((0, 2), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 2229, score: 2.0, epsilon: 0.33, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2239, score: 2.0, epsilon: 0.33, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2249, score: 0.0, epsilon: 0.33, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 2259, score: 0.0, epsilon: 0.33, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2269, score: 1.0, epsilon: 0.33, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2279, score: 2.0, epsilon: 0.33, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2289, score: 2.0, epsilon: 0.33, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2299, score: 0.0, epsilon: 0.32, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 2309, score: 0.0, epsilon: 0.32, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 2319, score: 0.0, epsilon: 0.32, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2329, score: 2.0, epsilon: 0.32, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2339, score: 0.0, epsilon: 0.32, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 2349, score: 0.0, epsilon: 0.32, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 0), 'H'), ((-3, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2359, score: 2.0, epsilon: 0.31, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2369, score: 2.0, epsilon: 0.31, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2379, score: 1.0, epsilon: 0.31, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2389, score: 0.0, epsilon: 0.31, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 2399, score: 0.0, epsilon: 0.31, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 2409, score: 2.0, epsilon: 0.31, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2419, score: 2.0, epsilon: 0.31, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2429, score: 1.0, epsilon: 0.30, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2439, score: 2.0, epsilon: 0.30, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2449, score: 2.0, epsilon: 0.30, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2459, score: 0.0, epsilon: 0.30, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 2469, score: 2.0, epsilon: 0.30, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2479, score: 1.0, epsilon: 0.30, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2489, score: 0.0, epsilon: 0.30, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 2499, score: 2.0, epsilon: 0.29, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2509, score: 0.0, epsilon: 0.29, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 0), 'H'), ((-2, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2519, score: 2.0, epsilon: 0.29, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2529, score: 2.0, epsilon: 0.29, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2539, score: 0.0, epsilon: 0.29, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 2549, score: 1.0, epsilon: 0.29, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2559, score: 2.0, epsilon: 0.29, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2569, score: 0.0, epsilon: 0.28, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')]), 'first_turn_left': True}\n",
            "Episode 2579, score: 2.0, epsilon: 0.28, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2589, score: 2.0, epsilon: 0.28, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2599, score: 2.0, epsilon: 0.28, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2609, score: 1.0, epsilon: 0.28, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2619, score: 0.0, epsilon: 0.28, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((0, 4), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 2629, score: 2.0, epsilon: 0.28, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2639, score: 2.0, epsilon: 0.27, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2649, score: 2.0, epsilon: 0.27, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2659, score: 2.0, epsilon: 0.27, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2669, score: 0.0, epsilon: 0.27, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 2679, score: 2.0, epsilon: 0.27, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2689, score: 0.0, epsilon: 0.27, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')]), 'first_turn_left': True}\n",
            "Episode 2699, score: 1.0, epsilon: 0.27, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2709, score: 1.0, epsilon: 0.27, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2719, score: 2.0, epsilon: 0.26, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2729, score: 0.0, epsilon: 0.26, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 2739, score: 2.0, epsilon: 0.26, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2749, score: 2.0, epsilon: 0.26, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2759, score: 2.0, epsilon: 0.26, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2769, score: 0.0, epsilon: 0.26, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 2779, score: 2.0, epsilon: 0.26, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2789, score: 0.0, epsilon: 0.26, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-3, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2799, score: 1.0, epsilon: 0.25, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2809, score: 2.0, epsilon: 0.25, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2819, score: 2.0, epsilon: 0.25, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2829, score: 0.0, epsilon: 0.25, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 2839, score: 0.0, epsilon: 0.25, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-3, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2849, score: 0.0, epsilon: 0.25, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 2859, score: 2.0, epsilon: 0.25, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2869, score: 2.0, epsilon: 0.25, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2879, score: 0.0, epsilon: 0.24, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2889, score: 0.0, epsilon: 0.24, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 2899, score: 2.0, epsilon: 0.24, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2909, score: 0.0, epsilon: 0.24, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((0, 4), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 2919, score: 1.0, epsilon: 0.24, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2929, score: 0.0, epsilon: 0.24, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((0, 4), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 2939, score: 2.0, epsilon: 0.24, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2949, score: 2.0, epsilon: 0.24, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2959, score: 2.0, epsilon: 0.24, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 2969, score: 1.0, epsilon: 0.23, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2979, score: 0.0, epsilon: 0.23, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((0, 4), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 2989, score: 0.0, epsilon: 0.23, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 2999, score: 2.0, epsilon: 0.23, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3009, score: 2.0, epsilon: 0.23, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3019, score: 1.0, epsilon: 0.23, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3029, score: 2.0, epsilon: 0.23, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3039, score: 2.0, epsilon: 0.23, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3049, score: 1.0, epsilon: 0.23, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3059, score: 0.0, epsilon: 0.22, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((0, 4), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 3069, score: 0.0, epsilon: 0.22, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')]), 'first_turn_left': True}\n",
            "Episode 3079, score: 1.0, epsilon: 0.22, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3089, score: 2.0, epsilon: 0.22, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3099, score: 1.0, epsilon: 0.22, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3109, score: 0.0, epsilon: 0.22, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 3119, score: 1.0, epsilon: 0.22, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3129, score: 2.0, epsilon: 0.22, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3139, score: 2.0, epsilon: 0.22, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3149, score: 2.0, epsilon: 0.22, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3159, score: 2.0, epsilon: 0.21, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3169, score: 2.0, epsilon: 0.21, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3179, score: 2.0, epsilon: 0.21, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3189, score: 1.0, epsilon: 0.21, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3199, score: 2.0, epsilon: 0.21, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3209, score: 0.0, epsilon: 0.21, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-2, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3219, score: 2.0, epsilon: 0.21, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3229, score: 2.0, epsilon: 0.21, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3239, score: 1.0, epsilon: 0.21, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3249, score: 2.0, epsilon: 0.21, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3259, score: 1.0, epsilon: 0.20, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3269, score: 2.0, epsilon: 0.20, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3279, score: 2.0, epsilon: 0.20, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3289, score: 2.0, epsilon: 0.20, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3299, score: 1.0, epsilon: 0.20, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3309, score: 2.0, epsilon: 0.20, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3319, score: 2.0, epsilon: 0.20, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3329, score: 2.0, epsilon: 0.20, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3339, score: 1.0, epsilon: 0.20, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3349, score: 2.0, epsilon: 0.20, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3359, score: 1.0, epsilon: 0.19, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3369, score: 1.0, epsilon: 0.19, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3379, score: 0.0, epsilon: 0.19, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 3389, score: 1.0, epsilon: 0.19, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-2, 1), 'P'), ((-2, 0), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3399, score: 2.0, epsilon: 0.19, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3409, score: 2.0, epsilon: 0.19, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3419, score: 1.0, epsilon: 0.19, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3429, score: 2.0, epsilon: 0.19, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3439, score: 2.0, epsilon: 0.19, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3449, score: 2.0, epsilon: 0.19, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3459, score: 2.0, epsilon: 0.19, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3469, score: 2.0, epsilon: 0.18, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3479, score: 2.0, epsilon: 0.18, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3489, score: 2.0, epsilon: 0.18, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3499, score: 2.0, epsilon: 0.18, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3509, score: 2.0, epsilon: 0.18, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3519, score: 2.0, epsilon: 0.18, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3529, score: 0.0, epsilon: 0.18, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 3539, score: 2.0, epsilon: 0.18, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3549, score: 1.0, epsilon: 0.18, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3559, score: 2.0, epsilon: 0.18, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3569, score: 2.0, epsilon: 0.18, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3579, score: 2.0, epsilon: 0.18, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3589, score: 1.0, epsilon: 0.17, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3599, score: 0.0, epsilon: 0.17, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 3609, score: 2.0, epsilon: 0.17, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3619, score: 2.0, epsilon: 0.17, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3629, score: 2.0, epsilon: 0.17, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3639, score: 2.0, epsilon: 0.17, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3649, score: 2.0, epsilon: 0.17, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3659, score: 2.0, epsilon: 0.17, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3669, score: 0.0, epsilon: 0.17, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3679, score: 2.0, epsilon: 0.17, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3689, score: 2.0, epsilon: 0.17, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3699, score: 2.0, epsilon: 0.17, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3709, score: 2.0, epsilon: 0.16, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3719, score: 2.0, epsilon: 0.16, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3729, score: 2.0, epsilon: 0.16, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3739, score: 1.0, epsilon: 0.16, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3749, score: 2.0, epsilon: 0.16, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3759, score: 2.0, epsilon: 0.16, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3769, score: 2.0, epsilon: 0.16, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3779, score: 2.0, epsilon: 0.16, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3789, score: 2.0, epsilon: 0.16, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3799, score: 1.0, epsilon: 0.16, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3809, score: 2.0, epsilon: 0.16, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3819, score: 2.0, epsilon: 0.16, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3829, score: 1.0, epsilon: 0.16, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3839, score: 1.0, epsilon: 0.16, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3849, score: 2.0, epsilon: 0.15, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3859, score: 1.0, epsilon: 0.15, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3869, score: 2.0, epsilon: 0.15, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3879, score: 2.0, epsilon: 0.15, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3889, score: 2.0, epsilon: 0.15, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3899, score: 2.0, epsilon: 0.15, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3909, score: 2.0, epsilon: 0.15, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3919, score: 2.0, epsilon: 0.15, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3929, score: 2.0, epsilon: 0.15, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3939, score: 2.0, epsilon: 0.15, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3949, score: 2.0, epsilon: 0.15, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3959, score: 1.0, epsilon: 0.15, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3969, score: 2.0, epsilon: 0.15, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 3979, score: 1.0, epsilon: 0.15, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 3989, score: 0.0, epsilon: 0.14, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 3999, score: 0.0, epsilon: 0.14, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 4009, score: 2.0, epsilon: 0.14, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4019, score: 0.0, epsilon: 0.14, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4029, score: 2.0, epsilon: 0.14, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4039, score: 2.0, epsilon: 0.14, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4049, score: 2.0, epsilon: 0.14, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4059, score: 0.0, epsilon: 0.14, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 4069, score: 1.0, epsilon: 0.14, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4079, score: 1.0, epsilon: 0.14, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4089, score: 1.0, epsilon: 0.14, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4099, score: 1.0, epsilon: 0.14, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4109, score: 1.0, epsilon: 0.14, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4119, score: 1.0, epsilon: 0.14, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4129, score: 1.0, epsilon: 0.14, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4139, score: 0.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4149, score: 2.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4159, score: 1.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4169, score: 2.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4179, score: 1.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4189, score: 2.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4199, score: 2.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4209, score: 2.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4219, score: 1.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4229, score: 2.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4239, score: 2.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4249, score: 2.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4259, score: 1.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4269, score: 2.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4279, score: 2.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4289, score: 2.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4299, score: 2.0, epsilon: 0.13, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4309, score: 0.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 4319, score: 2.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4329, score: 0.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((0, 4), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 4339, score: 2.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4349, score: 2.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4359, score: 0.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-2, 2), 'H'), ((-3, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 4369, score: 2.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4379, score: 2.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4389, score: 2.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4399, score: 2.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4409, score: 2.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4419, score: 2.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4429, score: 2.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4439, score: 2.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4449, score: 1.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'R', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 2), 'P'), ((0, 2), 'H'), ((1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 4459, score: 1.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4469, score: 0.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 4479, score: 2.0, epsilon: 0.12, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4489, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4499, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4509, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4519, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4529, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4539, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4549, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4559, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4569, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4579, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4589, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4599, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4609, score: 0.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((0, 4), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 4619, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4629, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4639, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4649, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4659, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4669, score: 2.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4679, score: 1.0, epsilon: 0.11, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4689, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4699, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4709, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4719, score: 1.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4729, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4739, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4749, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4759, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4769, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4779, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4789, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4799, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4809, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4819, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4829, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4839, score: 1.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4849, score: 0.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 4859, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4869, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4879, score: 1.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4889, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4899, score: 0.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 4909, score: 2.0, epsilon: 0.10, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4919, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4929, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4939, score: 1.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4949, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4959, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4969, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4979, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 4989, score: 1.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 4999, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5009, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5019, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5029, score: 0.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((0, 4), 'H'), ((-1, 4), 'H')]), 'first_turn_left': True}\n",
            "Episode 5039, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5049, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5059, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5069, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5079, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5089, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5099, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5109, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5119, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5129, score: 0.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((-2, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 5139, score: 1.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 5149, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5159, score: 2.0, epsilon: 0.09, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5169, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5179, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5189, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5199, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5209, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5219, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5229, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5239, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5249, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5259, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5269, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5279, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5289, score: 1.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 5299, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5309, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5319, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5329, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5339, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5349, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5359, score: 1.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 5369, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5379, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5389, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5399, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5409, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5419, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5429, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5439, score: 2.0, epsilon: 0.08, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5449, score: 1.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 5459, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5469, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5479, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5489, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5499, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5509, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5519, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5529, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5539, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5549, score: 0.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 5559, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5569, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5579, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5589, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5599, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5609, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5619, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5629, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5639, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5649, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5659, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5669, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5679, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5689, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5699, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5709, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5719, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5729, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5739, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5749, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5759, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5769, score: 1.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 5779, score: 2.0, epsilon: 0.07, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5789, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5799, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5809, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5819, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5829, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5839, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5849, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5859, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5869, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5879, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5889, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5899, score: 1.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 5909, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5919, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5929, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5939, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5949, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5959, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5969, score: 1.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-2, 1), 'H')]), 'first_turn_left': True}\n",
            "Episode 5979, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5989, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 5999, score: 1.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 6009, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6019, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6029, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6039, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6049, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6059, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6069, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6079, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6089, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6099, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6109, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6119, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6129, score: 0.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'R', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-2, 0), 'H'), ((-3, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6139, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6149, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6159, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6169, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6179, score: 2.0, epsilon: 0.06, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6189, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6199, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6209, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6219, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6229, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6239, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6249, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6259, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6269, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6279, score: 1.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 6289, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6299, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6309, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6319, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6329, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6339, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6349, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6359, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6369, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6379, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6389, score: 1.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 6399, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6409, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6419, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6429, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6439, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6449, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6459, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6469, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6479, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6489, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6499, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6509, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6519, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6529, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6539, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6549, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6559, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6569, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6579, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6589, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6599, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6609, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6619, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6629, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6639, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6649, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6659, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6669, score: 2.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6679, score: 1.0, epsilon: 0.05, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 6689, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6699, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6709, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6719, score: 1.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 6729, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6739, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6749, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6759, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6769, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6779, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6789, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6799, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6809, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6819, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6829, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6839, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6849, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6859, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6869, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6879, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6889, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6899, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6909, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6919, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6929, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6939, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6949, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6959, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6969, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6979, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 6989, score: 0.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 6999, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7009, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7019, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7029, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7039, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7049, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7059, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7069, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7079, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7089, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7099, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7109, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7119, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7129, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7139, score: 1.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 1, 0, 0, 1, 0]]), (6, 6)), reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['L', 'L', 'F', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((-1, 1), 'P'), ((-1, 0), 'P'), ((-1, -1), 'H'), ((0, -1), 'H')]), 'first_turn_left': True}\n",
            "Episode 7149, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7159, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7169, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7179, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7189, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7199, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7209, score: 0.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'L', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((-1, 3), 'H'), ((-1, 2), 'H')]), 'first_turn_left': True}\n",
            "Episode 7219, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7229, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7239, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7249, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7259, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7269, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7279, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7289, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7299, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7309, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7319, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7329, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7339, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7349, score: 2.0, epsilon: 0.04, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7359, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7369, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7379, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7389, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7399, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7409, score: 0.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'L'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((-2, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 7419, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7429, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7439, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7449, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7459, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7469, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7479, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7489, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7499, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7509, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7519, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7529, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7539, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7549, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7559, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7569, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7579, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7589, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7599, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7609, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7619, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7629, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7639, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7649, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7659, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7669, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7679, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7689, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7699, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7709, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7719, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7729, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7739, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7749, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7759, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7769, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7779, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7789, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7799, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7809, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7819, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7829, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7839, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7849, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7859, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7869, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7879, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7889, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7899, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7909, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7919, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7929, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7939, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7949, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7959, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7969, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7979, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7989, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 7999, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8009, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8019, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8029, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8039, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8049, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8059, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8069, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8079, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8089, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8099, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8109, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8119, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8129, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8139, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8149, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8159, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8169, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8179, score: 0.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((0, 4), 'H'), ((0, 5), 'H')]), 'first_turn_left': False}\n",
            "Episode 8189, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8199, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8209, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8219, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8229, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8239, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8249, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8259, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8269, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8279, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8289, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8299, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8309, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8319, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8329, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8339, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8349, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8359, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8369, score: 2.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8379, score: 0.0, epsilon: 0.03, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'F', 'F', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((0, 3), 'P'), ((0, 4), 'H'), ((0, 5), 'H')]), 'first_turn_left': False}\n",
            "Episode 8389, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8399, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8409, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8419, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8429, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8439, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8449, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8459, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8469, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8479, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8489, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8499, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8509, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8519, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8529, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8539, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8549, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8559, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8569, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8579, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8589, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8599, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8609, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8619, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8629, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8639, score: 0.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 8649, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8659, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8669, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8679, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8689, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8699, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8709, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8719, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8729, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8739, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8749, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8759, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8769, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8779, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8789, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8799, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8809, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8819, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8829, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8839, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8849, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8859, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8869, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8879, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8889, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8899, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8909, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8919, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8929, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8939, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8949, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8959, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8969, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8979, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8989, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 8999, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9009, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9019, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9029, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9039, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9049, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9059, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9069, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9079, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9089, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9099, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9109, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9119, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9129, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9139, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9149, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9159, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9169, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9179, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9189, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9199, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9209, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9219, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9229, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9239, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9249, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9259, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9269, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9279, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9289, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9299, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9309, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9319, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9329, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9339, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9349, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9359, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9369, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9379, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9389, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9399, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9409, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9419, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9429, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9439, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9449, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9459, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9469, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9479, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9489, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9499, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9509, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9519, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9529, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9539, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9549, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9559, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9569, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9579, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9589, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9599, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9609, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9619, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9629, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9639, score: 0.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'R', 'R'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 3), 'H'), ((0, 3), 'H')]), 'first_turn_left': True}\n",
            "Episode 9649, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9659, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9669, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9679, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9689, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9699, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9709, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9719, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9729, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9739, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9749, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9759, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9769, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9779, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9789, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9799, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9809, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9819, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9829, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9839, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9849, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9859, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9869, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9879, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9889, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9899, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9909, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9919, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9929, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9939, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9949, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9959, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9969, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9979, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9989, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Episode 9999, score: 2.0, epsilon: 0.02, reward_max: 2.0\n",
            "\ts_prime: (array([[1, 0, 0, 0, 0, 1],\n",
            "       [1, 0, 0, 0, 0, 1],\n",
            "       [0, 0, 1, 0, 1, 0]]), (6, 6)), reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['F', 'L', 'L', 'F'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((0, 1), 'H'), ((0, 2), 'P'), ((-1, 2), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')]), 'first_turn_left': True}\n",
            "Complete\n",
            "means =  1.5262\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$$$ rewards_all_episodes:  [0. 0. 0. ... 2. 2. 2.]\n",
            "$$$ rewards_all_episodes last 10 rewards =  [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
            "Frequency of unique rewards of rewards_all_episodes:\n",
            "[[   0.    1.    2.]\n",
            " [1812. 1114. 7074.]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1f38d2678388>\u001b[0m in \u001b[0;36m<cell line: 373>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0mrewards_all_episodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0mshow_every\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m     \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ]
    }
  ]
}