{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYVDKTD7KXZj0BJKX34l69",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AncaIoanaMuscalagiu/ProteinFoldingNotebooks/blob/main/Mine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "S3KW-rfNFPoZ"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "import gym\n",
        "from gym import (spaces, logger)\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "ACTION_TO_MEANING_2D = {1: (-1, 0), 2: (1, 0), 3: (0, -1), 4: (0, 1)}\n",
        "ACTION_TO_MEANING_3D = {1: (-1, 0, 0), 2: (1, 0, 0), 3: (0, -1, 0), 4: (0, 1, 0), 5: (0, 0, -1), 6: (0, 0, 1)}\n",
        "ACTION_TO_DIRECTION = {\n",
        "    (-1, 0): {'L': (0, -1), 'R': (0, 1), 'F': (-1, 0)},\n",
        "    (1, 0): {'L': (0, 1), 'R': (0, -1), 'F': (1, 0)},\n",
        "    (0, -1): {'L': (1, 0), 'R': (-1, 0), 'F': (0, -1)},\n",
        "    (0, 1): {'L': (0, -1), 'R': (1, 0), 'F': (0, 1)},\n",
        "}\n",
        "ACTION_TO_LRF = {\n",
        "    1: 'L',\n",
        "    2: 'R',\n",
        "    3: 'F'\n",
        "}\n",
        "LRF_TO_ACTION = {\n",
        "    'L': 1,\n",
        "    'R': 2,\n",
        "    'F': 3\n",
        "}\n",
        "ACTION_TO_MEANING_TRIANGULAR = {\n",
        "    1: (-1, 0), 2: (1, 0), 3: (0, -1), 4: (0, 1), 5: (1, 1), 6: (-1, -1)\n",
        "}\n",
        "\n",
        "\n",
        "def move_to_new_state_lrf(previous_move_direction, state, action):\n",
        "    if action not in {1, 2, 3}:\n",
        "        return\n",
        "\n",
        "    action_lrf = ACTION_TO_LRF[action]\n",
        "    current_move_direction = ACTION_TO_DIRECTION[previous_move_direction][action_lrf]\n",
        "    x1, y1 = state\n",
        "\n",
        "    new_state = (x1 + current_move_direction[0], y1 + current_move_direction[1])\n",
        "\n",
        "    return current_move_direction, new_state\n",
        "\n",
        "\n",
        "def move_to_new_state_3d(p1, p2, move_direction):\n",
        "    if move_direction not in {1, 2, 3, 4, 5, 6}:\n",
        "        return\n",
        "    x1, y1, z1 = p1\n",
        "\n",
        "    new_state = (x1 + (ACTION_TO_MEANING_3D[move_direction])[0], y1 + (ACTION_TO_MEANING_3D[move_direction])[1],\n",
        "                 z1 + (ACTION_TO_MEANING_3D[move_direction])[2])\n",
        "    if p2 == new_state:\n",
        "        return\n",
        "    return new_state\n",
        "\n",
        "\n",
        "def move_to_new_state_2d(p1, p2, move_direction):\n",
        "    if move_direction not in {1, 2, 3, 4}:\n",
        "        return\n",
        "\n",
        "    x1, y1 = p1\n",
        "\n",
        "    new_state = (x1 + (ACTION_TO_MEANING_2D[move_direction])[0], y1 + (ACTION_TO_MEANING_2D[move_direction])[1])\n",
        "    if p2 == new_state:\n",
        "        return\n",
        "    return new_state\n",
        "\n",
        "\n",
        "def move_to_new_state_triangular(p1, p2, move_direction):\n",
        "    if move_direction not in {1, 2, 3, 4, 5, 6}:\n",
        "        return\n",
        "\n",
        "    x1, y1 = p1\n",
        "    new_state = (\n",
        "        x1 + (ACTION_TO_MEANING_TRIANGULAR[move_direction])[0], y1 + (ACTION_TO_MEANING_TRIANGULAR[move_direction])[1])\n",
        "    if p2 == new_state:\n",
        "        return\n",
        "    return new_state\n",
        "\n",
        "import gym\n",
        "from gym import (spaces, utils, logger)\n",
        "import numpy as np\n",
        "\n",
        "class ProteinFoldingBaseEnv(gym.Env):\n",
        "    def __init__(self,\n",
        "                 seq,\n",
        "                 ):\n",
        "        self.seq = seq.upper()\n",
        "        self.is_trapped = False\n",
        "        self.done = False\n",
        "        if len(self.seq) <= 2:\n",
        "            return\n",
        "\n",
        "    def observe(self):\n",
        "        action_chain = self.actions\n",
        "        native_obs = np.zeros(shape=(len(self.seq) - 2,), dtype=int)\n",
        "        for i, item in enumerate(action_chain):\n",
        "            native_obs[i] = item\n",
        "        return native_obs\n",
        "\n",
        "    def _compute_reward(self):\n",
        "        curr_reward = self._compute_free_energy(self.state)\n",
        "        if self.is_trapped:\n",
        "            return -0.01\n",
        "        elif self.done:\n",
        "            return curr_reward\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def _compute_free_energy(self, chain):\n",
        "\n",
        "        path = list(chain.items())\n",
        "        total_energy = 0\n",
        "        for index in range(0, len(path)):\n",
        "            for jndex in range(index, len(path)):\n",
        "                if abs(index - jndex) >= 2:\n",
        "                    current_amino_acid_i = path[index][1]\n",
        "                    current_amino_acid_j = path[jndex][1]\n",
        "                    current_place_i = path[index][0]\n",
        "                    current_place_j = path[jndex][0]\n",
        "                    x_i = current_place_i[0]\n",
        "                    y_i = current_place_i[1]\n",
        "                    x_j = current_place_j[0]\n",
        "                    y_j = current_place_j[1]\n",
        "                    if current_amino_acid_i == 'H' and current_amino_acid_j == 'H' and (\n",
        "                            abs(x_i - x_j) + abs(y_i - y_j) == 1):\n",
        "                        total_energy += 1\n",
        "        return total_energy\n",
        "\n",
        "    def get_observation_info(self, next_state):\n",
        "        is_trapped = False\n",
        "        if len(self.state) < len(self.seq):\n",
        "            if set(self._get_adjacent_coords(next_state).values()).issubset(self.state.keys()):\n",
        "                is_trapped = True\n",
        "        obs = self.observe()\n",
        "        self.is_trapped = is_trapped\n",
        "        self.done = len(self.state) == len(self.seq) or is_trapped\n",
        "        reward = self._compute_reward()\n",
        "        info = {\n",
        "            'chain_length': len(self.state),\n",
        "            'seq_length': len(self.seq),\n",
        "            'actions': [str(i) for i in self.actions],\n",
        "            'is_trapped': is_trapped,\n",
        "            'state_chain': self.state,\n",
        "        }\n",
        "        return obs, reward, self.done, False, info\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        \"\"\"\n",
        "        seed the gym env\n",
        "        NOTE: this umbrella seed() will seed the end globally\n",
        "        it will seed:\n",
        "            action_space\n",
        "            np random (for uniform to_exploit)\n",
        "        \"\"\"\n",
        "        self.np_random, seed = utils.seeding.np_random(seed)\n",
        "\n",
        "        # NOTE: spaces sample use separate random number generator\n",
        "        # that lives in gym.spaces.prng. If you want action / observation\n",
        "        # space to sample deterministically you will need to seed separately\n",
        "        self.action_space.seed(seed)\n",
        "        # NOTE: agent also uses randomness, need to seed that separately\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        return [seed]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.lines as mlines\n",
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator, MaxNLocator)\n",
        "\n",
        "from IPython import display\n",
        "from sklearn.metrics import euclidean_distances\n",
        "\n",
        "\n",
        "def plot_print_rewards_stats(rewards_all_episodes,\n",
        "                             show_every,\n",
        "                             args,\n",
        "                             mode=\"show\",\n",
        "                             save_path=\"\"):\n",
        "    # unpack the args\n",
        "    seq = \"HHPPHH\"\n",
        "    seed = 42\n",
        "    num_episodes = 10000\n",
        "\n",
        "    # Calculate and print the average reward per show_every episodes\n",
        "    rewards_per_N_episodes = np.split(\n",
        "        np.array(rewards_all_episodes),\n",
        "        num_episodes\n",
        "    )\n",
        "    count = show_every\n",
        "\n",
        "    # for plotting\n",
        "    aggr_ep_rewards = {'ep': [], 'avg': [], 'max': [], 'min': []}\n",
        "\n",
        "    print(\"\\n********Stats per {} episodes********\\n\".format(show_every))\n",
        "    for r in rewards_per_N_episodes:\n",
        "        # print(count, \"avg: \", str(sum(r/show_every)))\n",
        "        # print(count, \"min: \", str(min(r)))\n",
        "        # print(count, \"max: \", str(max(r)))\n",
        "\n",
        "        aggr_ep_rewards['ep'].append(count)\n",
        "        aggr_ep_rewards['avg'].append(sum(r / show_every))\n",
        "        aggr_ep_rewards['min'].append(min(r))\n",
        "        aggr_ep_rewards['max'].append(max(r))\n",
        "\n",
        "        count += show_every\n",
        "\n",
        "    # Width, height in inches.\n",
        "    # default: [6.4, 4.8]\n",
        "    fig_width = 6.4\n",
        "    fig_height = 4.8\n",
        "    # adjust the height of the histogram\n",
        "    if np.array(rewards_all_episodes).max() - np.array(rewards_all_episodes).min() > 10:\n",
        "        fig_width = 6.5\n",
        "        fig_height = 6.5\n",
        "    fig, subplot = plt.subplots(figsize=(fig_width, fig_height))\n",
        "    # Be sure to only pick integer tick locations\n",
        "    subplot.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    # subplot.yaxis.set_major_locator(MultipleLocator(1))\n",
        "    subplot.yaxis.set_minor_locator(MultipleLocator(1))\n",
        "\n",
        "    subplot.set_xlabel('Episode Index')\n",
        "    subplot.set_ylabel('Episode Reward')\n",
        "\n",
        "    subplot.plot(aggr_ep_rewards['ep'], aggr_ep_rewards['avg'], label=\"average rewards\")\n",
        "    subplot.plot(aggr_ep_rewards['ep'], aggr_ep_rewards['max'], label=\"max rewards\")\n",
        "    subplot.plot(aggr_ep_rewards['ep'], aggr_ep_rewards['min'], label=\"min rewards\")\n",
        "\n",
        "    # Put a legend below current axis\n",
        "    subplot.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
        "                   fancybox=True, shadow=True, ncol=3)\n",
        "\n",
        "    # split the seq into chunks of 10 for the matplotlib title\n",
        "    chunks, chunk_size = len(seq), 10\n",
        "    seq_title_list = [\n",
        "        seq[i:i + chunk_size] + \"\\n\" for i in range(0, chunks, chunk_size)\n",
        "    ]\n",
        "    seq_title_str = ''.join(seq_title_list)\n",
        "\n",
        "    # print(\"Title: \", title)\n",
        "\n",
        "    plt.grid(True, which=\"major\", lw=1.2, linestyle='-')\n",
        "    plt.grid(True, which=\"minor\", lw=0.8, linestyle='--')\n",
        "    plt.tight_layout()\n",
        "    if mode == \"show\":\n",
        "        plt.show()\n",
        "    elif mode == \"save\":\n",
        "        # save the pdf fig with seq name\n",
        "        plt.savefig(\"{}Seq_{}-{}-Eps{}-Seed{}.png\".format(\n",
        "            save_path,  # \"./xxx\"\n",
        "            seq,\n",
        "            num_episodes,\n",
        "            seed,\n",
        "        ))\n",
        "    plt.close()\n",
        "\n",
        "def plot_moving_avg(scores, n=500, mode=\"show\", save_path=\"\"):\n",
        "    print(\"means = \", scores.mean())\n",
        "\n",
        "    # useful utility function for graphing the average\n",
        "    def moving_average(a, n=n):\n",
        "        ret = np.cumsum(a, dtype=float)\n",
        "        ret[n:] = ret[n:] - ret[:-n]\n",
        "        return ret[n - 1:] / n\n",
        "\n",
        "    plt.plot(moving_average(scores, n=n))\n",
        "    # plt.plot(moving_average(opt_scores, n=500))\n",
        "    # plt.plot(moving_average(rand_scores, n=500))\n",
        "    if mode == \"show\":\n",
        "        plt.show()\n",
        "    elif mode == \"save\":\n",
        "        # save the pdf fig with seq name\n",
        "        plt.savefig(save_path + \"moving_avg-\" + str(n) + \".png\")\n",
        "    plt.close()\n",
        "    \n",
        "\n",
        "def plot_2D_foleded_protein(labelled_conf):\n",
        "    \"\"\"\n",
        "    input:\n",
        "        labelled_conf:\n",
        "            transformed file sequence of xy coords with state:\n",
        "            ((x,y), 'H|P')\n",
        "            e.g:\n",
        "            [((0, 0), 'H'),\n",
        "            ((0, 1), 'H'),...\n",
        "            ((3, 1), 'P')]\n",
        "    output:\n",
        "        plot.show\n",
        "    \"\"\"\n",
        "\n",
        "    plt.rc('axes', labelsize=18)\n",
        "    plt.rc('xtick', labelsize=18)\n",
        "    plt.rc('ytick', labelsize=18)\n",
        "\n",
        "\n",
        "    fig = plt.figure()\n",
        "    subplot = fig.add_subplot()\n",
        "    subplot.title.set_text(\"Folded Protein\")\n",
        "    x = [t[0][0] for t in labelled_conf]\n",
        "    y = [t[0][1] for t in labelled_conf]\n",
        "\n",
        "    H_points = [t[0] for t in labelled_conf if t[1] == 'H']\n",
        "    P_points = [t[0] for t in labelled_conf if t[1] == 'P']\n",
        "\n",
        "    max_xval = np.max(x)\n",
        "    max_yval = np.max(y)\n",
        "\n",
        "    total_max = max(max_xval, max_yval)\n",
        "    min_xval = np.min(x)\n",
        "    min_yval = np.min(y)\n",
        "\n",
        "    total_min = min(min_xval, min_yval)\n",
        "    subplot.set_xlim(total_min - 0.1, total_max+0.1)\n",
        "    subplot.set_ylim(total_min - 0.1, total_max+0.1 )\n",
        "\n",
        "    subplot.set_aspect('equal')  # , adjustable='box')\n",
        "\n",
        "    subplot.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    subplot.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    subplot.plot(\n",
        "        x, y,\n",
        "        color='cornflowerblue',\n",
        "        linewidth=4,\n",
        "        label=\"backbone\",\n",
        "    )\n",
        "\n",
        "    subplot.plot(\n",
        "        [h[0] for h in H_points],\n",
        "        [h[1] for h in H_points],\n",
        "        'o',\n",
        "        color='royalblue',\n",
        "        markersize=14,\n",
        "        label=\"H\",\n",
        "    )\n",
        "\n",
        "    for index in range(0, len(labelled_conf)):\n",
        "        for jndex in range(index, len(labelled_conf)):\n",
        "            if abs(index - jndex) >= 2:\n",
        "                current_amino_acid_i = labelled_conf[index][1]\n",
        "                current_amino_acid_j = labelled_conf[jndex][1]\n",
        "                current_place_i = labelled_conf[index][0]\n",
        "                current_place_j = labelled_conf[jndex][0]\n",
        "                x_i = current_place_i[0]\n",
        "                y_i = current_place_i[1]\n",
        "                x_j = current_place_j[0]\n",
        "                y_j = current_place_j[1]\n",
        "                if current_amino_acid_i == 'H' and current_amino_acid_j == 'H' and (\n",
        "                        abs(x_i - x_j) + abs(y_i - y_j) == 1):\n",
        "                    subplot.plot([x_i, x_j], [y_i, y_j], '--', color='mediumblue')\n",
        "                    subplot.plot([x_i, x_j], [y_i, y_j], 'o', color='mediumblue', markersize=14,)\n",
        "\n",
        "    subplot.plot(\n",
        "        [p[0] for p in P_points],\n",
        "        [p[1] for p in P_points],\n",
        "        'o',\n",
        "        color='orange',\n",
        "        fillstyle='none',\n",
        "        markersize=14,\n",
        "        label=\"P\",\n",
        "    )\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def save_2d_protein_to_xyz(labelled_conf, output_file_name):\n",
        "    output_file = open(output_file_name, \"w\")\n",
        "    for atom_item in labelled_conf:\n",
        "        coords, atom = atom_item\n",
        "        x, y = coords\n",
        "        z = 0\n",
        "        output_file.write(\"{}\\t {}\\t {}\\t {}\\t\\n\".format(atom, x, y, z))\n",
        "    output_file.close()\n",
        "\n",
        "\n",
        "def plot_3D_foleded_protein(labelled_conf):\n",
        "    \"\"\"\n",
        "    input:\n",
        "        labelled_conf:\n",
        "            transformed file sequence of xy coords with state:\n",
        "            ((x,y), 'H|P')\n",
        "            e.g:\n",
        "            [((0, 0), 'H'),\n",
        "            ((0, 1), 'H'),...\n",
        "            ((3, 1), 'P')]\n",
        "    output:\n",
        "        plot.show\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    plt.rc('axes', labelsize=25)\n",
        "    plt.rc('xtick', labelsize=21)\n",
        "    plt.rc('ytick', labelsize=21)\n",
        "    x = [t[0][0] for t in labelled_conf]\n",
        "    y = [t[0][1] for t in labelled_conf]\n",
        "    z = [t[0][2] for t in labelled_conf]\n",
        "\n",
        "    H_points = [t[0] for t in labelled_conf if t[1] == 'H']\n",
        "    P_points = [t[0] for t in labelled_conf if t[1] == 'P']\n",
        "\n",
        "    fig = plt.figure()\n",
        "    subplot = fig.add_subplot(projection='3d')\n",
        "    subplot.title.set_text(\"Folded Protein\")\n",
        "\n",
        "    max_xval = np.max(x)\n",
        "    max_yval = np.max(y)\n",
        "    max_zval = np.max(z)\n",
        "    total_max = max(max_xval, max_yval, max_zval)\n",
        "    min_xval = np.min(x)\n",
        "    min_yval = np.min(y)\n",
        "    min_zval = np.min(z)\n",
        "    total_min = min(min_xval, min_yval, min_zval)\n",
        "    subplot.set_xlim(total_min, total_max)\n",
        "    subplot.set_ylim(total_min, total_max)\n",
        "    subplot.set_zlim(total_min, total_max)\n",
        "\n",
        "\n",
        "    subplot.grid(linewidth=0.6, linestyle=':')\n",
        "\n",
        "\n",
        "    subplot.set_aspect('equal')  # , adjustable='box')\n",
        "\n",
        "\n",
        "    subplot.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    subplot.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    subplot.zaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    subplot.set_xlabel(\"x coord\")\n",
        "    subplot.set_ylabel(\"y coord\")\n",
        "    subplot.set_zlabel(\"z coord\")\n",
        "\n",
        "\n",
        "    subplot.plot(\n",
        "        x, y, z,\n",
        "        color='cornflowerblue',\n",
        "        linewidth=4,\n",
        "        label=\"backbone\",\n",
        "    )\n",
        "\n",
        "\n",
        "    subplot.plot(\n",
        "        [h[0] for h in H_points],\n",
        "        [h[1] for h in H_points],\n",
        "        [h[2] for h in H_points],\n",
        "        'o',\n",
        "        color='royalblue',\n",
        "        markersize=14,\n",
        "        label=\"H\",\n",
        "    )\n",
        "\n",
        "    subplot.plot(\n",
        "        [p[0] for p in P_points],\n",
        "        [p[1] for p in P_points],\n",
        "        [p[2] for p in P_points],\n",
        "        'o',\n",
        "        color='orange',\n",
        "        fillstyle='none',\n",
        "        markersize=14,\n",
        "        label=\"P\",\n",
        "    )\n",
        "\n",
        "    for index in range(0, len(labelled_conf)):\n",
        "        for jndex in range(index, len(labelled_conf)):\n",
        "            if abs(index - jndex) >= 2:\n",
        "                current_amino_acid_i = labelled_conf[index][1]\n",
        "                current_amino_acid_j = labelled_conf[jndex][1]\n",
        "                current_place_i = labelled_conf[index][0]\n",
        "                current_place_j = labelled_conf[jndex][0]\n",
        "                x_i = current_place_i[0]\n",
        "                y_i = current_place_i[1]\n",
        "                z_i = current_place_i[2]\n",
        "                x_j = current_place_j[0]\n",
        "                y_j = current_place_j[1]\n",
        "                z_j = current_place_j[2]\n",
        "                if current_amino_acid_i == 'H' and current_amino_acid_j == 'H' and (\n",
        "                        abs(x_i - x_j) + abs(y_i - y_j) + abs(z_i - z_j) == 1):\n",
        "                    subplot.plot([x_i, x_j], [y_i, y_j],[z_i,z_j], '--', color='mediumblue')\n",
        "                    subplot.plot([x_i, x_j], [y_i, y_j], [z_i,z_j], 'o', color='mediumblue', markersize=14, )\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_loss(episodes, losses):\n",
        "    # unpack the args\n",
        "\n",
        "    # Width, height in inches.\n",
        "    # default: [6.4, 4.8]\n",
        "\n",
        "\n",
        "    fig, subplot = plt.subplots(\n",
        "    )\n",
        "\n",
        "    # subplot.yaxis.set_major_locator(MultipleLocator(1))\n",
        "\n",
        "\n",
        "    subplot.set_xlabel('Episode Index')\n",
        "    subplot.set_ylabel('Episode Reward')\n",
        "\n",
        "    subplot.plot(episodes,losses, label=\"Losses\")\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "PXzz_FHZFgDQ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from gym import (spaces)\n",
        "\n",
        "\n",
        "class ProteinFolding2DEnv(ProteinFoldingBaseEnv):\n",
        "    def __init__(self, seq):\n",
        "        super().__init__(seq)\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.actions = []\n",
        "        self.state = OrderedDict(\n",
        "            {\n",
        "                (0, 0): self.seq[0],\n",
        "                (1, 0): self.seq[1],\n",
        "            }\n",
        "        )\n",
        "        self.done = len(self.seq) == 2\n",
        "        obs = self.observe()\n",
        "        return obs\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        if mode == \"human\":\n",
        "            plot_2D_foleded_protein(\n",
        "                list(self.state.items()),\n",
        "            )"
      ],
      "metadata": {
        "id": "aQHb2fS5FxiU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "import gym\n",
        "from gym import (spaces, logger)\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "class ProteinFoldingSquareEnv(ProteinFolding2DEnv):\n",
        "    def __init__(self, seq):\n",
        "        super().__init__(seq)\n",
        "        self.action_space = spaces.Discrete(start=1, n=4)\n",
        "        self.observation_space = spaces.Box(low=0, high=3,\n",
        "                                            shape=(len(self.seq) - 2,),\n",
        "                                            dtype=int)\n",
        "    def step(self, action):\n",
        "        if not self.action_space.contains(action):\n",
        "            raise ValueError(\"%r (%s) invalid\" % (action, type(action)))\n",
        "        previous = list(self.state.keys())[-1]\n",
        "        previous2 = list(self.state.keys())[-2]\n",
        "        next_state = move_to_new_state_2d(\n",
        "            previous,\n",
        "            previous2,\n",
        "            action\n",
        "        )\n",
        "        idx = len(self.state)\n",
        "        if next_state is None or next_state in self.state:\n",
        "            return (None, None, False, False, {})\n",
        "        self.actions.append(action)\n",
        "        try:\n",
        "            self.state.update({next_state: self.seq[idx]})\n",
        "        except IndexError:\n",
        "            logger.error('All molecules have been placed! Nothing can be added to the protein chain.')\n",
        "            raise\n",
        "        return self.get_observation_info(next_state)\n",
        "\n",
        "    def _get_adjacent_coords(self, coords):\n",
        "        x, y = coords\n",
        "        adjacent_coords = {\n",
        "            0: (x - 1, y),\n",
        "            1: (x, y - 1),\n",
        "            2: (x, y + 1),\n",
        "            3: (x + 1, y),\n",
        "        }\n",
        "        return adjacent_coords\n",
        "from gym.envs.registration import register\n",
        "register(\n",
        "    id='ProteinFoldingSquareEnv',\n",
        "    entry_point=ProteinFoldingSquareEnv,\n",
        "    max_episode_steps=100000,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BTSV_naF2bv",
        "outputId": "9a2b3284-a8dc-4d40-83d5-324776a6c1e3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:542: UserWarning: \u001b[33mWARN: Overriding environment ProteinFoldingSquareEnv\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {spec.id}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class FCN_QNet(nn.Module):\n",
        "    \"\"\"\n",
        "    action value function, Q(S, a)\n",
        "    produce the actions in parallel as output vector,\n",
        "    and choose the max\n",
        "    \"\"\"\n",
        "    def __init__(self, insize, outsize):\n",
        "        \"\"\"\n",
        "        insize ==> input size\n",
        "            == size of the observation space\n",
        "        outsize ==> output size\n",
        "            == number of actions\n",
        "        \"\"\"\n",
        "        super(FCN_QNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(insize, 256)\n",
        "        self.fc2 = nn.Linear(256, 84)\n",
        "        self.fc3 = nn.Linear(84, outsize)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        standard 3-layer fully connected NN\n",
        "        \"\"\"\n",
        "        x = x.to(device)  # for CUDA\n",
        "        # print(\"input x.size() = \", x.size())\n",
        "        #x = x.view(x.size(0),-1)\n",
        "        # may encounter view memory error\n",
        "        # RuntimeError: view size is not compatible with input tensor's size and stride\n",
        "        # (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
        "        x = x.reshape(x.size(0),-1)\n",
        "        # print(\"after x.view ---> input x.size() = \", x.size())\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    def sample_action(self, obs, epsilon):\n",
        "      \"\"\"\n",
        "      greedy epsilon choose\n",
        "      \"\"\"\n",
        "      coin = random.random()\n",
        "      if coin < epsilon:\n",
        "          # print(\"coin < epsilon\", coin, epsilon)\n",
        "          # for 3actionStateEnv use [0,1,2]\n",
        "          value = random.randint(1,4)\n",
        "          return value\n",
        "      else:\n",
        "          # print(\"exploit\")\n",
        "          out = self.forward(obs)\n",
        "     \n",
        "          return out.argmax().item()+1\n"
      ],
      "metadata": {
        "id": "P6V7C8iPGLgx"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import optimizer\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# hyperparameters\n",
        "discount_rate = 0.98  # discount rate\n",
        "BATCH_SIZE = 32\n",
        "RELATIVE_MODELS_PATH = \"./models/\"\n",
        "train_times = 10  # number of times train was run in a loop\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def sample_action_from_q_table(env, Q_table, current_state, epsilon):\n",
        "    \"\"\"\n",
        "    greedy epsilon choose\n",
        "    \"\"\"\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "        action = env.action_space.sample()\n",
        "    else:\n",
        "        current_state = tuple(current_state)\n",
        "        if current_state not in Q_table.keys():\n",
        "            return env.action_space.sample()\n",
        "        action_value_table = Q_table[current_state]\n",
        "        max_value = 0\n",
        "        action = env.action_space.sample()\n",
        "        for a in action_value_table:\n",
        "            if action_value_table[a] >= max_value:\n",
        "                max_value = action_value_table[a]\n",
        "                action = a\n",
        "\n",
        "    return action\n",
        "\n",
        "\n",
        "def sample_action_from_ann(env, model, current_state, epsilon):\n",
        "    \"\"\"\n",
        "    greedy epsilon choose\n",
        "    \"\"\"\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "        action = env.action_space.sample()\n",
        "    else:\n",
        "        action = model(torch.from_numpy(current_state).float().unsqueeze(0))\n",
        "        action = action.argmax().item() + 1\n",
        "\n",
        "    return action\n",
        "\n",
        "\n",
        "def train(policy_net, target_net, memory, optimizer, losses):\n",
        "    \"\"\"\n",
        "    core algorithm of Deep policy_net-learning\n",
        "\n",
        "    do this training once per evaluation of the environment\n",
        "    run evaluation once and train X times\n",
        "    \"\"\"\n",
        "    if memory.size() < 50*10:\n",
        "        return losses\n",
        "\n",
        "    for i in range(train_times):\n",
        "        s, a, r, s_prime, done = memory.sample(BATCH_SIZE)\n",
        "\n",
        "        state_values = policy_net(s)\n",
        "        q_values_state = state_values.gather(1, a - 1)\n",
        "        max_q_prime = target_net(s_prime).max(1)[0].unsqueeze(1)\n",
        "        q_values_expected = r + discount_rate * max_q_prime * done\n",
        "        loss = F.smooth_l1_loss(q_values_state, q_values_expected)\n",
        "        losses.append(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return losses\n",
        "\n",
        "\n",
        "def save_model(model, environment, sequence, model_type):\n",
        "    file_name = environment + \"/\" + model_type + \"_\" + sequence\n",
        "    path = RELATIVE_MODELS_PATH + file_name + \".pth\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(\"Successfully saved model: \" + file_name)\n",
        "\n"
      ],
      "metadata": {
        "id": "q2rXtZUqGj86"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# imports\n",
        "from collections import deque\n",
        "# Note: deque is pronounced as “deck.” The name stands for double-ended queue.\n",
        "import random\n",
        "import pickle\n",
        "# pytorch deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# if gpu is to be used\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class ReplayBuffer():\n",
        "    \"\"\"\n",
        "    for DQN (off-policy RL), big buffer of experience\n",
        "    you don't update weights of the NN as you run\n",
        "    through the environment, instead you save\n",
        "    your experience of the environment to this ReplayBuffer\n",
        "    It has a max-size to fit in certain examples\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, buffer_limit):\n",
        "        self.buffer = deque(maxlen=buffer_limit)\n",
        "\n",
        "    def put(self, transition):\n",
        "        self.buffer.append(transition)\n",
        "\n",
        "    def sample(self, n):\n",
        "        mini_batch = random.sample(self.buffer, n)\n",
        "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
        "\n",
        "        for transition in mini_batch:\n",
        "            # a tuple that tells us what the state was\n",
        "            # at a particular point in time\n",
        "            # we store the current state, the action we chose,\n",
        "            # the state we ended up in, and whether finished or not\n",
        "            s, a, r, s_prime, done_mask = transition\n",
        "            s_lst.append(s)\n",
        "            a_lst.append([a])\n",
        "            r_lst.append([r])\n",
        "            s_prime_lst.append(s_prime)\n",
        "            done_mask_lst.append([done_mask])\n",
        "\n",
        "        # converting the list to a single numpy.ndarray with numpy.array()\n",
        "        # before converting to a tensor\n",
        "        s_lst = np.array(s_lst)\n",
        "        a_lst = np.array(a_lst)\n",
        "        r_lst = np.array(r_lst)\n",
        "        s_prime_lst = np.array(s_prime_lst)\n",
        "        done_mask_lst = np.array(done_mask_lst)\n",
        "\n",
        "\n",
        "        return torch.tensor(s_lst, device=device, dtype=torch.float), torch.tensor(a_lst, device=device), \\\n",
        "               torch.tensor(r_lst, device=device), torch.tensor(s_prime_lst, device=device, dtype=torch.float), \\\n",
        "               torch.tensor(done_mask_lst, device=device)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def save(self, save_path):\n",
        "        \"\"\"save in .pkl file\"\"\"\n",
        "        with open(save_path, 'wb') as handle:\n",
        "            pickle.dump(self.buffer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    def load(self, file_path):\n",
        "        \"\"\"load a .pkl file\"\"\"\n",
        "        with open(file_path, 'rb') as handle:\n",
        "            self.buffer = pickle.load(handle)\n"
      ],
      "metadata": {
        "id": "RBVVe3izGuka"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ExponentialDecay(episode, num_episodes,\n",
        "                min_exploration_rate, max_exploration_rate,\n",
        "                exploration_decay_rate=5,\n",
        "                start_decay=0):\n",
        "    decay_duration = num_episodes - start_decay\n",
        "    exploration_rate = max_exploration_rate\n",
        "    if episode > start_decay:\n",
        "        exploration_rate = min_exploration_rate + \\\n",
        "            (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate*(episode-start_decay)/decay_duration)\n",
        "    return exploration_rate\n",
        "\n",
        "def LinearDecay(episode, num_episodes,\n",
        "                min_exploration_rate, max_exploration_rate,\n",
        "                start_decay=0):\n",
        "    decay_duration = num_episodes - start_decay\n",
        "    exploration_rate = max_exploration_rate\n",
        "    if episode > start_decay:\n",
        "        exploration_rate = min_exploration_rate + \\\n",
        "                            (decay_duration-(episode-start_decay))/decay_duration\n",
        "        # print(\"(decay_duration-(episode-start_decay))/decay_duration = \", (decay_duration-(episode-start_decay))/decay_duration)\n",
        "    # print(\"exploration_rate = \", exploration_rate)\n",
        "    return exploration_rate\n"
      ],
      "metadata": {
        "id": "9A-4isuKGxLN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "# import csv\n",
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "def one_hot_state(state_arr, action_depth):\n",
        "    # print(\"after catting first_two_actions, state_arr = \", state_arr, state_arr.dtype, state_arr.shape)\n",
        "    state_arr = F.one_hot(torch.from_numpy(state_arr), num_classes=action_depth)\n",
        "    state_arr = state_arr.numpy()  # q.sample_action expects numpy arr\n",
        "    return state_arr\n",
        "\n",
        "\n",
        "seq = \"HHPPHH\" # Our input sequence\n",
        "seed = 42  # read the seed from CMD\n",
        "num_episodes = 10000  # number of episodes\n",
        "\n",
        "max_steps_per_episode = len(seq) - 2\n",
        "\n",
        "learning_rate = 0.0005\n",
        "discount_rate = 0.9\n",
        "# Exploration parameters\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0\n",
        "\n",
        "# render settings\n",
        "show_every = num_episodes // 1000  # for plot_print_rewards_stats\n",
        "\n",
        "rewards_all_episodes = np.zeros(\n",
        "    (num_episodes,),\n",
        "    # dtype=np.int32\n",
        ")\n",
        "reward_max = 0\n",
        "num_trapped = 0\n",
        "\n",
        "decay_mode = \"exponential\"  # exponential, cosine, linear\n",
        "exploration_decay_rate = 5  # for exponential decay\n",
        "start_decay = 0  # for exponential and linear\n",
        "\n",
        "env = ProteinFoldingSquareEnv(seq)\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "env.seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "env.action_space.seed(seed)\n",
        "initial_state = env.reset()\n",
        "\n",
        "\n",
        "print(\"initial state/obs:\")\n",
        "print(initial_state)\n",
        "\n",
        "# Get number of actions from gym action space\n",
        "n_observations = len(seq)-2\n",
        "\n",
        "col_length = env.observation_space.shape[0]\n",
        "\n",
        "n_actions = env.action_space.n+1\n",
        "hidden_size, num_layers, = 256, 2\n",
        "print(\"n_actions = \", n_actions)\n",
        "memory = ReplayBuffer(60000)\n",
        "policy_net = FCN_QNet(col_length * n_actions,n_actions-1).to(device)\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
        "target_net =FCN_QNet(col_length * n_actions,n_actions-1).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "losses = []\n",
        "eps = []\n",
        "for n_episode in range(num_episodes):\n",
        "    # = epsilon = max(min_exploration_rate, max_exploration_rate - exploration_decay_rate*(n_episode/200)) # linear annealing\n",
        "    if decay_mode == \"exponential\":\n",
        "        epsilon = ExponentialDecay(\n",
        "            n_episode,\n",
        "            num_episodes,\n",
        "            min_exploration_rate,\n",
        "            max_exploration_rate,\n",
        "            exploration_decay_rate=exploration_decay_rate,\n",
        "            start_decay=start_decay,\n",
        "        )\n",
        "    elif decay_mode == \"linear\":\n",
        "        epsilon = LinearDecay(\n",
        "            n_episode,\n",
        "            num_episodes,\n",
        "            min_exploration_rate,\n",
        "            max_exploration_rate,\n",
        "            start_decay=start_decay,\n",
        "        )\n",
        "\n",
        "    # reset the environment\n",
        "    # Initialize the environment and state\n",
        "    s = env.reset()\n",
        "    \n",
        "    s = one_hot_state(s,n_actions)\n",
        "    done = False\n",
        "    score = 0.0\n",
        "\n",
        "    for step in range(max_steps_per_episode):\n",
        "\n",
        "        a = policy_net.sample_action(torch.from_numpy(s).float().unsqueeze(0), epsilon)\n",
        "\n",
        "        s_prime, r, done, truncated, info = env.step(a)\n",
        "\n",
        "        while s_prime is None:\n",
        "            # retry until action is not colliding\n",
        "            # print(\"retry sample another action...\")\n",
        "            a = policy_net.sample_action(torch.from_numpy(s).float().unsqueeze(0), epsilon)\n",
        "            # print(\"retried action = \", a)\n",
        "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
        "            s_prime, r, done, truncated, info = env.step(a)\n",
        "        s_prime=one_hot_state(s_prime,n_actions)\n",
        "        q_value = 0\n",
        "        max_value = 0\n",
        "        action = a\n",
        "        done_mask = 0.0 if done else 1.0\n",
        "        memory.put((s, a, r, s_prime, done_mask))\n",
        "        if memory.size() >= BATCH_SIZE :\n",
        "            eps.append(n_episode + 0.01*step)\n",
        "\n",
        "        if done:\n",
        "            if len(info['actions']) == (len(seq) - 2):\n",
        "                pass\n",
        "            else:\n",
        "                num_trapped += 1\n",
        "            break\n",
        "        s = s_prime\n",
        "\n",
        "    losses = train(policy_net, target_net, memory, optimizer, losses)\n",
        "\n",
        "    # Update the target network, copying all weights and biases in DQN\n",
        "    if n_episode % 100 == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "    score = r\n",
        "    rewards_all_episodes[n_episode] = score\n",
        "    # update max reward found so far\n",
        "\n",
        "    print(\"Episode {}, score: {:.1f}, epsilon: {:.2f}, reward_max: {}\".format(\n",
        "        n_episode,\n",
        "        score,\n",
        "        epsilon,\n",
        "        reward_max,\n",
        "    ))\n",
        "    print(f\"\\ts_prime: {s_prime}, reward: {r}, done: {done}, info: {info}\")\n",
        "    if score > reward_max:\n",
        "        print(\"found new highest reward = \", score)\n",
        "        reward_max = score\n",
        "        env.render()\n",
        "\n",
        "print('Complete')\n",
        "\n",
        "# ***** plot the stats and save in save_path *****\n",
        "\n",
        "plot_print_rewards_stats(\n",
        "    rewards_all_episodes,\n",
        "    1,\n",
        "    \"args\",\n",
        "   \"show\",\n",
        "    \"fe\"\n",
        ")\n",
        "plot_moving_avg(rewards_all_episodes, mode=\"show\", save_path=\"v\")\n",
        "\n",
        "plot_loss(\n",
        "    eps,\n",
        "    losses\n",
        ")\n",
        "env.close()\n",
        "\n",
        "print(\"\\nnum_trapped = \", num_trapped)\n",
        "\n",
        "# last line of the output is the max reward\n",
        "print(\"\\nreward_max = \", reward_max)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4Sq4gXs0GoAA",
        "outputId": "b0711868-da72-4023-9329-443615b235eb"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial state/obs:\n",
            "[0 0 0 0]\n",
            "n_actions =  5\n",
            "Episode 0, score: 0.0, epsilon: 1.00, reward_max: 0\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '2', '4', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((3, 0), 'P'), ((3, 1), 'H'), ((2, 1), 'H')])}\n",
            "Episode 1, score: 0.0, epsilon: 1.00, reward_max: 0\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '2', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((3, -1), 'H'), ((3, -2), 'H')])}\n",
            "Episode 2, score: 0.0, epsilon: 1.00, reward_max: 0\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '1', '1', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((0, 1), 'P'), ((-1, 1), 'H'), ((-1, 2), 'H')])}\n",
            "Episode 3, score: 0.0, epsilon: 1.00, reward_max: 0\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((1, -2), 'P'), ((0, -2), 'H'), ((-1, -2), 'H')])}\n",
            "Episode 4, score: 0.0, epsilon: 1.00, reward_max: 0\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '1', '4', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((0, 1), 'P'), ((0, 2), 'H'), ((1, 2), 'H')])}\n",
            "Episode 5, score: 1.0, epsilon: 1.00, reward_max: 0\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '2', '3', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((2, 1), 'P'), ((2, 0), 'H'), ((3, 0), 'H')])}\n",
            "found new highest reward =  1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 6, score: 0.0, epsilon: 1.00, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '2', '2', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((2, -1), 'P'), ((3, -1), 'H'), ((3, 0), 'H')])}\n",
            "Episode 7, score: 0.0, epsilon: 1.00, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((1, 2), 'P'), ((0, 2), 'H'), ((-1, 2), 'H')])}\n",
            "Episode 8, score: 0.0, epsilon: 1.00, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '3', '1', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((1, -2), 'P'), ((0, -2), 'H'), ((0, -3), 'H')])}\n",
            "Episode 9, score: 0.0, epsilon: 1.00, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '2', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((3, -1), 'H'), ((4, -1), 'H')])}\n",
            "Episode 10, score: 0.0, epsilon: 1.00, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '2', '4', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((2, 1), 'P'), ((2, 2), 'H'), ((3, 2), 'H')])}\n",
            "Episode 11, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '2', '4', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((2, 1), 'P'), ((2, 2), 'H'), ((3, 2), 'H')])}\n",
            "Episode 12, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '2', '4', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((2, 1), 'P'), ((2, 2), 'H'), ((2, 3), 'H')])}\n",
            "Episode 13, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '2', '3', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((3, 0), 'P'), ((3, -1), 'H'), ((4, -1), 'H')])}\n",
            "Episode 14, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '4', '2', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((1, 2), 'P'), ((2, 2), 'H'), ((2, 3), 'H')])}\n",
            "Episode 15, score: 1.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 1 0]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '1', '1', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((0, 1), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')])}\n",
            "Episode 16, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '2', '3', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((3, 0), 'P'), ((3, -1), 'H'), ((2, -1), 'H')])}\n",
            "Episode 17, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '4', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((2, 2), 'H'), ((3, 2), 'H')])}\n",
            "Episode 18, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '4', '4', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((1, 2), 'P'), ((1, 3), 'H'), ((0, 3), 'H')])}\n",
            "Episode 19, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '2', '2', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((2, 1), 'P'), ((3, 1), 'H'), ((4, 1), 'H')])}\n",
            "Episode 20, score: 1.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '2', '3', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((2, 1), 'P'), ((2, 0), 'H'), ((2, -1), 'H')])}\n",
            "Episode 21, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '2', '3', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((3, 0), 'P'), ((3, -1), 'H'), ((3, -2), 'H')])}\n",
            "Episode 22, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '1', '1', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((0, -1), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')])}\n",
            "Episode 23, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '1', '1', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((0, -1), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')])}\n",
            "Episode 24, score: 1.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 1 0]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '4', '1', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((1, 2), 'P'), ((0, 2), 'H'), ((0, 1), 'H')])}\n",
            "Episode 25, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '2', '4', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((3, 0), 'P'), ((3, 1), 'H'), ((4, 1), 'H')])}\n",
            "Episode 26, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '2', '3', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((3, 0), 'P'), ((3, -1), 'H'), ((4, -1), 'H')])}\n",
            "Episode 27, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '2', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((3, 1), 'H'), ((4, 1), 'H')])}\n",
            "Episode 28, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '3', '3', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((1, -2), 'P'), ((1, -3), 'H'), ((0, -3), 'H')])}\n",
            "Episode 29, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '3', '3', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((1, -2), 'P'), ((1, -3), 'H'), ((0, -3), 'H')])}\n",
            "Episode 30, score: 0.0, epsilon: 0.99, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '2', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((3, 1), 'H'), ((3, 0), 'H')])}\n",
            "Episode 31, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '3', '2', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((1, -2), 'P'), ((2, -2), 'H'), ((2, -1), 'H')])}\n",
            "Episode 32, score: 1.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 1 0]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((1, -2), 'H')])}\n",
            "Episode 33, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '4', '2', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((1, 2), 'P'), ((2, 2), 'H'), ((2, 1), 'H')])}\n",
            "Episode 34, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '2', '2', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((2, -1), 'P'), ((3, -1), 'H'), ((4, -1), 'H')])}\n",
            "Episode 35, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '2', '2', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((3, 0), 'P'), ((4, 0), 'H'), ((4, 1), 'H')])}\n",
            "Episode 36, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '2', '4', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((3, 0), 'P'), ((3, 1), 'H'), ((4, 1), 'H')])}\n",
            "Episode 37, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '4', '4', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((1, 2), 'P'), ((1, 3), 'H'), ((1, 4), 'H')])}\n",
            "Episode 38, score: 1.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '2', '3', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((2, 1), 'P'), ((2, 0), 'H'), ((2, -1), 'H')])}\n",
            "Episode 39, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((1, -2), 'P'), ((0, -2), 'H'), ((-1, -2), 'H')])}\n",
            "Episode 40, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '1', '3', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((0, -1), 'P'), ((0, -2), 'H'), ((1, -2), 'H')])}\n",
            "Episode 41, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '1', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((0, -1), 'P'), ((-1, -1), 'H'), ((-2, -1), 'H')])}\n",
            "Episode 42, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '4', '2', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((1, 2), 'P'), ((2, 2), 'H'), ((2, 1), 'H')])}\n",
            "Episode 43, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((1, 2), 'P'), ((0, 2), 'H'), ((-1, 2), 'H')])}\n",
            "Episode 44, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '2', '2', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((3, 0), 'P'), ((4, 0), 'H'), ((5, 0), 'H')])}\n",
            "Episode 45, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '2', '2', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((2, -1), 'P'), ((3, -1), 'H'), ((3, -2), 'H')])}\n",
            "Episode 46, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '2', '2', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((2, 1), 'P'), ((3, 1), 'H'), ((3, 0), 'H')])}\n",
            "Episode 47, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '1', '4', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((0, 1), 'P'), ((0, 2), 'H'), ((-1, 2), 'H')])}\n",
            "Episode 48, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '3', '3', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((1, -2), 'P'), ((1, -3), 'H'), ((2, -3), 'H')])}\n",
            "Episode 49, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '4', '4', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((1, 2), 'P'), ((1, 3), 'H'), ((1, 4), 'H')])}\n",
            "Episode 50, score: 0.0, epsilon: 0.98, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '3', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((2, -2), 'H'), ((2, -3), 'H')])}\n",
            "Episode 51, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '2', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((3, 1), 'H'), ((3, 2), 'H')])}\n",
            "Episode 52, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '2', '3', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((3, 0), 'P'), ((3, -1), 'H'), ((3, -2), 'H')])}\n",
            "Episode 53, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '3', '2', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((1, -2), 'P'), ((2, -2), 'H'), ((3, -2), 'H')])}\n",
            "Episode 54, score: 1.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '2', '3', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((2, 1), 'P'), ((2, 0), 'H'), ((3, 0), 'H')])}\n",
            "Episode 55, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '2', '4', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((3, 0), 'P'), ((3, 1), 'H'), ((2, 1), 'H')])}\n",
            "Episode 56, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '1', '4', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((0, 1), 'P'), ((0, 2), 'H'), ((-1, 2), 'H')])}\n",
            "Episode 57, score: 1.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '2', '4', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((2, -1), 'P'), ((2, 0), 'H'), ((3, 0), 'H')])}\n",
            "Episode 58, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '4', '4', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((1, 2), 'P'), ((1, 3), 'H'), ((0, 3), 'H')])}\n",
            "Episode 59, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '2', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((3, -1), 'H'), ((3, 0), 'H')])}\n",
            "Episode 60, score: 1.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '2', '3', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((2, 1), 'P'), ((2, 0), 'H'), ((3, 0), 'H')])}\n",
            "Episode 61, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '2', '3', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((3, 0), 'P'), ((3, -1), 'H'), ((2, -1), 'H')])}\n",
            "Episode 62, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '3', '1', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((1, -2), 'P'), ((0, -2), 'H'), ((0, -3), 'H')])}\n",
            "Episode 63, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '2', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((3, -1), 'H'), ((3, 0), 'H')])}\n",
            "Episode 64, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '2', '4', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((3, 0), 'P'), ((3, 1), 'H'), ((3, 2), 'H')])}\n",
            "Episode 65, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '1', '3', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((0, -1), 'P'), ((0, -2), 'H'), ((-1, -2), 'H')])}\n",
            "Episode 66, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '2', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((3, 1), 'H'), ((3, 2), 'H')])}\n",
            "Episode 67, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '4', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((2, 2), 'H'), ((3, 2), 'H')])}\n",
            "Episode 68, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '1', '1', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((0, -1), 'P'), ((-1, -1), 'H'), ((-1, -2), 'H')])}\n",
            "Episode 69, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '2', '2', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((2, -1), 'P'), ((3, -1), 'H'), ((4, -1), 'H')])}\n",
            "Episode 70, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '3', '3', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((1, -2), 'P'), ((1, -3), 'H'), ((1, -4), 'H')])}\n",
            "Episode 71, score: 0.0, epsilon: 0.97, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '2', '2', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((2, 1), 'P'), ((3, 1), 'H'), ((3, 2), 'H')])}\n",
            "Episode 72, score: 0.0, epsilon: 0.96, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '4', '2', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((1, 2), 'P'), ((2, 2), 'H'), ((2, 1), 'H')])}\n",
            "Episode 73, score: 0.0, epsilon: 0.96, reward_max: 1\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '4', '2', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((1, 2), 'P'), ((2, 2), 'H'), ((3, 2), 'H')])}\n",
            "Episode 74, score: 0.0, epsilon: 0.96, reward_max: 1\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 1 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '3', '1', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((1, -2), 'P'), ((0, -2), 'H'), ((0, -3), 'H')])}\n",
            "Episode 75, score: 2.0, epsilon: 0.96, reward_max: 1\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "found new highest reward =  2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9001, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9002, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9003, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9004, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9005, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9006, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9007, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9008, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9009, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9010, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9011, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9012, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9013, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9014, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9015, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9016, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9017, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9018, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9019, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9020, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9021, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9022, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9023, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9024, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9025, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9026, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9027, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9028, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9029, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9030, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9031, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9032, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9033, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9034, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9035, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9036, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9037, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9038, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9039, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9040, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9041, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9042, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9043, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9044, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9045, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9046, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9047, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9048, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9049, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9050, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9051, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9052, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9053, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9054, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9055, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9056, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9057, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9058, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9059, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9060, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9061, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9062, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9063, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9064, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9065, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9066, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9067, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9068, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9069, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9070, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9071, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9072, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9073, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9074, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9075, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9076, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9077, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9078, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9079, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9080, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9081, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9082, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9083, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9084, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9085, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9086, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9087, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9088, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9089, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9090, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9091, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9092, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9093, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9094, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9095, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9096, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9097, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9098, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9099, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9100, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9101, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9102, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9103, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9104, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9105, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9106, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9107, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9108, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9109, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9110, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9111, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9112, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9113, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9114, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9115, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9116, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9117, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9118, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9119, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9120, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9121, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9122, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9123, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9124, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9125, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9126, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9127, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9128, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9129, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9130, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9131, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9132, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9133, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9134, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9135, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9136, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9137, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9138, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9139, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9140, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9141, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9142, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9143, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9144, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9145, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9146, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9147, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9148, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9149, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9150, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9151, score: 1.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '2', '3', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((2, 1), 'P'), ((2, 0), 'H'), ((2, -1), 'H')])}\n",
            "Episode 9152, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9153, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9154, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9155, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9156, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9157, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9158, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9159, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9160, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9161, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9162, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9163, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9164, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9165, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9166, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9167, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9168, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9169, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9170, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9171, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9172, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9173, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9174, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9175, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9176, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9177, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9178, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9179, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9180, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9181, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9182, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9183, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9184, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9185, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9186, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9187, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9188, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9189, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9190, score: 0.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '4', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((2, 2), 'H'), ((3, 2), 'H')])}\n",
            "Episode 9191, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9192, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9193, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9194, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9195, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9196, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9197, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9198, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9199, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9200, score: 1.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '3', '1', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((1, -2), 'P'), ((0, -2), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9201, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9202, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9203, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9204, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9205, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9206, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9207, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9208, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9209, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9210, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9211, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9212, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9213, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9214, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9215, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9216, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9217, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9218, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9219, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9220, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9221, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9222, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9223, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9224, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9225, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9226, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9227, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9228, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9229, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9230, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9231, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9232, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9233, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9234, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9235, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9236, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9237, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9238, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9239, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9240, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9241, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9242, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9243, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9244, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9245, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9246, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9247, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9248, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9249, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9250, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9251, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9252, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9253, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9254, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9255, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9256, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9257, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9258, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9259, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9260, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9261, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9262, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9263, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9264, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9265, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9266, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9267, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9268, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9269, score: 1.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '2', '3', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((2, 1), 'P'), ((2, 0), 'H'), ((3, 0), 'H')])}\n",
            "Episode 9270, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9271, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9272, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9273, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9274, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9275, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9276, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9277, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9278, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9279, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9280, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9281, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9282, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9283, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9284, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9285, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9286, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9287, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9288, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9289, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9290, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9291, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9292, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9293, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9294, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9295, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9296, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9297, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9298, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9299, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9300, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9301, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9302, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9303, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9304, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9305, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9306, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9307, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9308, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9309, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9310, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9311, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9312, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9313, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9314, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9315, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9316, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9317, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9318, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9319, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9320, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9321, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9322, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9323, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9324, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9325, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9326, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9327, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9328, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9329, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9330, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9331, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9332, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9333, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9334, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9335, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9336, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9337, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9338, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9339, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9340, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9341, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9342, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9343, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9344, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9345, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9346, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9347, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9348, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9349, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9350, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9351, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9352, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9353, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9354, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9355, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9356, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9357, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9358, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9359, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9360, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9361, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9362, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9363, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9364, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9365, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9366, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9367, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9368, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9369, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9370, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9371, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9372, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9373, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9374, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9375, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9376, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9377, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9378, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9379, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9380, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9381, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9382, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9383, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9384, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9385, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9386, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9387, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9388, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9389, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9390, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9391, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9392, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9393, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9394, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9395, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9396, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9397, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9398, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9399, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9400, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9401, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9402, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9403, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9404, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9405, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9406, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9407, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9408, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9409, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9410, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9411, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9412, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9413, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9414, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9415, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9416, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9417, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9418, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9419, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9420, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9421, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9422, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9423, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9424, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9425, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9426, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9427, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9428, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9429, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9430, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9431, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9432, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9433, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9434, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9435, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9436, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9437, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9438, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9439, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9440, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9441, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9442, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9443, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9444, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9445, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9446, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9447, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9448, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9449, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9450, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9451, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9452, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9453, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9454, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9455, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9456, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9457, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9458, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9459, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9460, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9461, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9462, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9463, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9464, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9465, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9466, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9467, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9468, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9469, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9470, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9471, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9472, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9473, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9474, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9475, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9476, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9477, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9478, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9479, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9480, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9481, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9482, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9483, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9484, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9485, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9486, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9487, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9488, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9489, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9490, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9491, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9492, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9493, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9494, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9495, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9496, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9497, score: 1.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 1 0]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((1, -2), 'H')])}\n",
            "Episode 9498, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9499, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9500, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9501, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9502, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9503, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9504, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9505, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9506, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9507, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9508, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9509, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9510, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9511, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9512, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9513, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9514, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9515, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9516, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9517, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9518, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9519, score: 1.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['3', '1', '1', '4'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, -1), 'P'), ((0, -1), 'P'), ((-1, -1), 'H'), ((-1, 0), 'H')])}\n",
            "Episode 9520, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9521, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9522, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9523, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9524, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9525, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9526, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9527, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9528, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9529, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9530, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9531, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9532, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9533, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9534, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9535, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9536, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9537, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9538, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9539, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9540, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9541, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9542, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9543, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9544, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9545, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9546, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9547, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9548, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9549, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9550, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9551, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9552, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9553, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9554, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9555, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9556, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9557, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9558, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9559, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9560, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9561, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9562, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9563, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9564, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9565, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9566, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9567, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9568, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9569, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9570, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9571, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9572, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9573, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9574, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9575, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9576, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9577, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9578, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9579, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9580, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9581, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9582, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9583, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9584, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9585, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9586, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9587, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9588, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9589, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9590, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9591, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9592, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9593, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9594, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9595, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9596, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9597, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9598, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9599, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9600, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9601, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9602, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9603, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9604, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9605, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9606, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9607, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9608, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9609, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9610, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9611, score: 0.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '3', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((2, -2), 'H'), ((3, -2), 'H')])}\n",
            "Episode 9612, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9613, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9614, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9615, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9616, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9617, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9618, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9619, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9620, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9621, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9622, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9623, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9624, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9625, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9626, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9627, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9628, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9629, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9630, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9631, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9632, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9633, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9634, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9635, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9636, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9637, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9638, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9639, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9640, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9641, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9642, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9643, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9644, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9645, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9646, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9647, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9648, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9649, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9650, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9651, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9652, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9653, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9654, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9655, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9656, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9657, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9658, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9659, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9660, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9661, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9662, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9663, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9664, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9665, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9666, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9667, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9668, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9669, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9670, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9671, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9672, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9673, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9674, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9675, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9676, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9677, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9678, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9679, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9680, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9681, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9682, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9683, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9684, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9685, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9686, score: 1.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 1 0]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '4', '1', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((1, 2), 'P'), ((0, 2), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9687, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9688, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9689, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9690, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9691, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9692, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9693, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9694, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9695, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9696, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9697, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9698, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9699, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9700, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9701, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9702, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9703, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9704, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9705, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9706, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9707, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9708, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9709, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9710, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9711, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9712, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9713, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9714, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9715, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9716, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9717, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9718, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9719, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9720, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9721, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9722, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9723, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9724, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9725, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9726, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9727, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9728, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9729, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9730, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9731, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9732, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9733, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9734, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9735, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9736, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9737, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9738, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9739, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9740, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9741, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9742, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9743, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9744, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9745, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9746, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9747, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9748, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9749, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9750, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9751, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9752, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9753, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9754, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9755, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9756, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9757, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9758, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9759, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9760, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9761, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9762, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9763, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9764, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9765, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9766, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9767, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9768, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9769, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9770, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9771, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9772, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9773, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9774, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9775, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9776, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9777, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9778, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9779, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9780, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9781, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9782, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9783, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9784, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9785, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9786, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9787, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9788, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9789, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9790, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9791, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9792, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9793, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9794, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9795, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9796, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9797, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9798, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9799, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9800, score: 0.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]], reward: 0, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '4', '2'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((2, 2), 'H'), ((3, 2), 'H')])}\n",
            "Episode 9801, score: 1.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 1 0]], reward: 1, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['4', '1', '1', '3'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((1, 1), 'P'), ((0, 1), 'P'), ((-1, 1), 'H'), ((-1, 0), 'H')])}\n",
            "Episode 9802, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9803, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9804, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9805, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9806, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9807, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9808, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9809, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9810, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9811, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9812, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9813, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9814, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9815, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9816, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9817, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9818, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9819, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9820, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9821, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9822, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9823, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9824, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9825, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9826, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9827, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9828, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9829, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9830, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9831, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9832, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9833, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9834, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9835, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9836, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9837, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9838, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9839, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9840, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9841, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9842, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9843, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9844, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9845, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9846, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9847, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9848, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9849, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9850, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9851, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9852, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9853, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9854, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9855, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9856, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9857, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9858, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9859, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9860, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9861, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9862, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9863, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9864, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9865, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9866, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9867, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9868, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9869, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9870, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9871, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9872, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9873, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9874, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9875, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9876, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9877, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9878, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9879, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9880, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9881, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9882, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9883, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9884, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9885, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9886, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9887, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9888, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9889, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9890, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9891, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9892, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9893, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9894, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9895, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9896, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9897, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9898, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9899, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9900, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9901, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9902, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9903, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9904, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9905, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9906, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9907, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9908, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9909, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9910, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9911, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9912, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9913, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9914, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9915, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9916, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9917, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9918, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9919, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9920, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9921, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9922, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9923, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9924, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9925, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9926, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9927, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9928, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9929, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9930, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9931, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9932, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9933, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9934, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9935, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9936, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9937, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9938, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9939, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9940, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9941, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9942, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9943, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9944, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9945, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9946, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9947, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9948, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9949, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9950, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9951, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9952, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9953, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9954, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9955, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9956, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9957, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9958, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9959, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9960, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9961, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9962, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9963, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9964, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9965, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9966, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9967, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9968, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9969, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9970, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9971, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9972, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9973, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9974, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9975, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9976, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9977, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9978, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9979, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9980, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9981, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9982, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9983, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9984, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9985, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9986, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9987, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9988, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9989, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9990, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9991, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9992, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9993, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9994, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9995, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '3', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, -1), 'P'), ((1, -1), 'H'), ((0, -1), 'H')])}\n",
            "Episode 9996, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9997, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9998, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Episode 9999, score: 2.0, epsilon: 0.01, reward_max: 2\n",
            "\ts_prime: [[0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]], reward: 2, done: True, info: {'chain_length': 6, 'seq_length': 6, 'actions': ['2', '4', '1', '1'], 'is_trapped': False, 'state_chain': OrderedDict([((0, 0), 'H'), ((1, 0), 'H'), ((2, 0), 'P'), ((2, 1), 'P'), ((1, 1), 'H'), ((0, 1), 'H')])}\n",
            "Complete\n",
            "\n",
            "********Stats per 1 episodes********\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "means =  1.3938\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-34952ddbf03f>\u001b[0m in \u001b[0;36m<cell line: 168>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0mplot_moving_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards_all_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"show\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"v\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m plot_loss(\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-7ba898655cff>\u001b[0m in \u001b[0;36mplot_loss\u001b[0;34m(episodes, losses)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0msubplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Episode Reward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0msubplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Losses\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    505\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (39969,) and (98760,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J5Gvn-80yRnI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}